<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: OriginalStuff/nn.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_ca2321bf04872c45e422808b66ea4cec.html">OriginalStuff</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="headertitle"><div class="title">nn.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="OriginalStuff_2nn_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="preprocessor">#ifndef LLM_CPP__NN_HPP_</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="preprocessor">#define LLM_CPP__NN_HPP_</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span> </div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="preprocessor">#include &lt;unistd.h&gt;</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="preprocessor">#include &lt;iomanip&gt;</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="preprocessor">#include &lt;memory&gt;</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="preprocessor">#include &lt;random&gt;</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span> </div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="preprocessor">#include &quot;<a class="code" href="OriginalStuff_2llmc_2rand_8h.html">llmc/rand.h</a>&quot;</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="preprocessor">#include &quot;<a class="code" href="OriginalStuff_2tensor__util_8hpp.html">tensor_util.hpp</a>&quot;</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span> </div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span> </div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment">/* #include &quot;absl/algorithm/container.h&quot;</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment">#include &quot;absl/log/check.h&quot;</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="comment">#include &quot;absl/log/log.h&quot;</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="comment">#include &quot;absl/strings/string_view.h&quot;</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="comment">#include &quot;absl/types/span.h&quot; */</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#include &quot;<a class="code" href="OriginalStuff_2abseil-cpp_2absl_2algorithm_2container_8h.html">abseil-cpp/absl/algorithm/container.h</a>&quot;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="preprocessor">#include &quot;<a class="code" href="OriginalStuff_2abseil-cpp_2absl_2log_2check_8h.html">abseil-cpp/absl/log/check.h</a>&quot;</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="preprocessor">#include &quot;<a class="code" href="OriginalStuff_2abseil-cpp_2absl_2log_2log_8h.html">abseil-cpp/absl/log/log.h</a>&quot;</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="preprocessor">#include &quot;<a class="code" href="OriginalStuff_2abseil-cpp_2absl_2strings_2string__view_8h.html">abseil-cpp/absl/strings/string_view.h</a>&quot;</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="preprocessor">#include &quot;<a class="code" href="OriginalStuff_2abseil-cpp_2absl_2types_2span_8h.html">abseil-cpp/absl/types/span.h</a>&quot;</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span> </div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span> </div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span> </div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacenn.html">nn</a> {</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span> </div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="preprocessor">#ifdef EIGEN_USE_GPU</span></div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span>Eigen::GpuStreamDevice g_stream;</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>Eigen::GpuDevice g_device(&amp;g_stream);</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span><a class="code hl_class" href="classEigen_1_1ThreadPoolTempl.html">Eigen::ThreadPool</a> <a class="code hl_variable" href="namespacenn.html#aceb3ca07330f23a6bffe93e606fcc6d8">g_thread_pool</a>(16 <span class="comment">/* number of threads in pool */</span>);</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>Eigen::ThreadPoolDevice g_device(&amp;<a class="code hl_variable" href="namespacenn.html#aceb3ca07330f23a6bffe93e606fcc6d8">g_thread_pool</a>,</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>                                 12 <span class="comment">/* number of threads to use */</span>);</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span> </div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span><a class="code hl_struct" href="structmt19937__state.html">mt19937_state</a> <a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>;</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span> </div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacenn.html#af51d93c61a072d59ba2e321b7fac681c">ManualSeed</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> seed) {</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>  <a class="code hl_function" href="llmc_2rand_8h.html#ab64d400dcc18bac40a0c38b316caa406">manual_seed</a>(&amp;<a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>, seed);</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>}</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span> </div>
<div class="foldopen" id="foldopen00044" data-start="{" data-end="}">
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno"><a class="line" href="namespacenn.html#ad8c9dfda0a9717b1cce402b73aadb8d7">   44</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacenn.html#afd34dfbb2119f475e4582064af7a06f0">ConstantFill</a>(<a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;float&gt;</a> weight, <span class="keywordtype">float</span> <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>) {</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span><span class="preprocessor">#ifdef EIGEN_USE_GPU</span></div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>  std::vector&lt;float&gt; w(weight.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>);</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>  g_device.memcpyHostToDevice(weight.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>(), w.data(),</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>                              <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * w.size());</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>  <a class="code hl_function" href="namespaceabsl.html#a1b228348b0d7cd46a5d9a1d4daf702cb">absl::c_fill</a>(weight, <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>);</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>}</div>
</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span> </div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacenn.html#aa7f7fc1fcad89e0745dbae4bfad4d356">UniformFill</a>(<a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;float&gt;</a> weight, <span class="keywordtype">float</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a66a6152caa0d2dec6985ed86838ba876">from</a> = 0.0,</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>                        <span class="keywordtype">float</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a633ab603a49d0a046734a0f3e6de45e9">to</a> = 1.0) {</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span><span class="preprocessor">#ifdef EIGEN_USE_GPU</span></div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>  std::vector&lt;float&gt; w(weight.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>());</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>  <a class="code hl_function" href="llmc_2rand_8h.html#aaf0aeafba5647f2ad3bb2cae66e5ed44">uniform_</a>(w.data(), w.size(), <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a66a6152caa0d2dec6985ed86838ba876">from</a>, <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a633ab603a49d0a046734a0f3e6de45e9">to</a>, &amp;<a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>);</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>  g_device.memcpyHostToDevice(weight.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>(), w.data(),</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>                              <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * w.size());</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>  <a class="code hl_function" href="llmc_2rand_8h.html#aaf0aeafba5647f2ad3bb2cae66e5ed44">uniform_</a>(weight.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>(), weight.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(), <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a66a6152caa0d2dec6985ed86838ba876">from</a>, <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a633ab603a49d0a046734a0f3e6de45e9">to</a>, &amp;<a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>);</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>}</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span> </div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacenn.html#a7a0bfd75fc17c62ba9e681cd3d346efc">NormalFill</a>(<a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;float&gt;</a> weight, <span class="keywordtype">float</span> mean = 0.0,</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>                       <span class="keywordtype">float</span> <a class="code hl_namespace" href="namespacestd.html">std</a> = 1.0) {</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span><span class="preprocessor">#ifdef EIGEN_USE_GPU</span></div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>  std::vector&lt;float&gt; w(weight.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>());</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>  <a class="code hl_function" href="llmc_2rand_8h.html#a486e23d6acb57456d73173c03f66a052">normal_</a>(w.data(), w.size(), mean, <a class="code hl_namespace" href="namespacestd.html">std</a>, &amp;<a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>);</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>  g_device.memcpyHostToDevice(weight.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>(), w.data(),</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>                              <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * w.size());</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>  <a class="code hl_function" href="llmc_2rand_8h.html#a486e23d6acb57456d73173c03f66a052">normal_</a>(weight.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>(), weight.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(), mean, <a class="code hl_namespace" href="namespacestd.html">std</a>, &amp;<a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>);</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>}</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span> </div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacenn.html#a5268109b8c87089a840f743713f8781f">KaimingUniformFill</a>(<a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;float&gt;</a> weight, <span class="keywordtype">int</span> in_features) {</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> bound = std::sqrt(1.0f / in_features);</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span><span class="preprocessor">#ifdef EIGEN_USE_GPU</span></div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>  std::vector&lt;float&gt; w(weight.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>());</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>  <a class="code hl_function" href="llmc_2rand_8h.html#aaf0aeafba5647f2ad3bb2cae66e5ed44">uniform_</a>(w.data(), w.size(), -bound, bound, &amp;<a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>);</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>  g_device.memcpyHostToDevice(weight.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>(), w.data(),</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>                              <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * w.size());</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>  <a class="code hl_function" href="llmc_2rand_8h.html#aaf0aeafba5647f2ad3bb2cae66e5ed44">uniform_</a>(weight.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>(), weight.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(), -bound, bound, &amp;<a class="code hl_variable" href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">g_mt19937_state</a>);</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>}</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span> </div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacenn.html#acb3bf801e394f195e8cece47de7b5311">UpperTriangularWithNegativeInf</a>(</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>    <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;float&gt;::Matrix</a> matrix) {</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>  <span class="keyword">using </span>MatrixXf =</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>      <a class="code hl_class" href="classEigen_1_1Matrix.html">Eigen::Matrix&lt;float, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;</a>;</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>  MatrixXf m = MatrixXf::Zero(matrix.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), matrix.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>  m.triangularView&lt;<a class="code hl_enumvalue" href="group__enums.html#gga39e3366ff5554d731e7dc8bb642f83cdae38aad7d66fecfb213fce453edff4c7a">Eigen::StrictlyUpper</a>&gt;().setConstant(</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>      -std::numeric_limits&lt;float&gt;::infinity());</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span><span class="preprocessor">#ifdef EIGEN_USE_GPU</span></div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>  g_device.memcpyHostToDevice(matrix.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a735ad83edfacfcb9173e59ed861e6bbf">data</a>(), m.<a class="code hl_function" href="classEigen_1_1internal_1_1TensorLazyEvaluatorReadOnly.html#a9be5f49eeb9fb048cc4f036588a41fc5">data</a>(),</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>                              <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * matrix.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>  g_device.memcpy(matrix.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a735ad83edfacfcb9173e59ed861e6bbf">data</a>(), m.<a class="code hl_function" href="classEigen_1_1internal_1_1TensorLazyEvaluatorReadOnly.html#a9be5f49eeb9fb048cc4f036588a41fc5">data</a>(), <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * matrix.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>}</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span> </div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacenn.html#ace7109b820ab3e99ec8c4fbfe7c0f13e">OntHot</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;int&gt;::ConstFlat</a> target,</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>                   <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;float&gt;::Matrix</a> label) {</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>  <span class="keywordtype">int</span> batch_size = target.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>(), num_class = label.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>  <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(batch_size, label.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> &lt; batch_size; ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>) {</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>    <span class="keywordtype">int</span> ix = target(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>);</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a4bd2e815ca2f702a4b6aa744b1ff3b82">CHECK_LT</a>(ix, num_class);</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>    label(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>, ix) = 1.0f;</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>  }</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>}</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span> </div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span><span class="keyword">inline</span> std::pair&lt;int, int&gt; <a class="code hl_function" href="namespacenn.html#a2b75086de2e32662267822633e0399d7">SplitRange</a>(<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2strings_2cord__analysis_8cc.html#a3fab45bb4d7cd7e889bdf00080096e8e">total</a>, <span class="keywordtype">int</span> idx, <span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__test_8cc.html#a76f11d9a0a47b94f72c2d0e77fb32240">n</a>) {</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="namespaceEigen_1_1numext.html#a5cda5c90c4e51bbe6611e423fd9c176f">q</a> = <a class="code hl_variable" href="abseil-cpp_2absl_2strings_2cord__analysis_8cc.html#a3fab45bb4d7cd7e889bdf00080096e8e">total</a> / <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__test_8cc.html#a76f11d9a0a47b94f72c2d0e77fb32240">n</a>;</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>  <span class="keywordtype">int</span> r = <a class="code hl_variable" href="abseil-cpp_2absl_2strings_2cord__analysis_8cc.html#a3fab45bb4d7cd7e889bdf00080096e8e">total</a> % <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__test_8cc.html#a76f11d9a0a47b94f72c2d0e77fb32240">n</a>;</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>  <span class="keywordflow">if</span> (idx &lt; r) {</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>    <span class="keywordflow">return</span> {(<a class="code hl_variable" href="namespaceEigen_1_1numext.html#a5cda5c90c4e51bbe6611e423fd9c176f">q</a> + 1) * idx, (q + 1) * (idx + 1)};</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>    <span class="keywordflow">return</span> {<a class="code hl_variable" href="namespaceEigen_1_1numext.html#a5cda5c90c4e51bbe6611e423fd9c176f">q</a> * idx + r, <a class="code hl_variable" href="namespaceEigen_1_1numext.html#a5cda5c90c4e51bbe6611e423fd9c176f">q</a> * (idx + 1) + r};</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>  }</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>}</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span> </div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno"><a class="line" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcf">  126</a></span><span class="keyword">enum</span> <a class="code hl_enumeration" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcf">DataType</a> : <span class="keywordtype">int</span> { <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa619d8e532169cd16e25ef103f28e3213">DT_FLOAT</a> = 1, <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfae00f2994306b9bd91c2165b87d5502f3">DT_HALF</a> = 2, <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa6a6aeedaa380640cdd4933339270f7cd">DT_INT32</a> = 3 };</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span> </div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span><span class="comment">// Validates type T for whether it is a supported DataType.</span></div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span><span class="keyword">template</span> &lt;<span class="keyword">class</span> T&gt;</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno"><a class="line" href="structnn_1_1IsValidDataType.html">  130</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1IsValidDataType.html">IsValidDataType</a>;</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span> </div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span><span class="comment">// DataTypeToEnum&lt;T&gt;::v() and DataTypeToEnum&lt;T&gt;::value are the DataType</span></div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span><span class="comment">// constants for T, e.g. DataTypeToEnum&lt;float&gt;::v() is DT_FLOAT.</span></div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span><span class="keyword">template</span> &lt;<span class="keyword">class</span> T&gt;</div>
<div class="foldopen" id="foldopen00135" data-start="{" data-end="};">
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno"><a class="line" href="structnn_1_1DataTypeToEnum.html">  135</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum</a> {</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>  <span class="keyword">static_assert</span>(<a class="code hl_struct" href="structnn_1_1IsValidDataType.html">IsValidDataType&lt;T&gt;::value</a>, <span class="stringliteral">&quot;Specified Data Type not supported&quot;</span>);</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>};  <span class="comment">// Specializations below</span></div>
</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span> </div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span><span class="comment">// EnumToDataType&lt;VALUE&gt;::Type is the type for DataType constant VALUE, e.g.</span></div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span><span class="comment">// EnumToDataType&lt;DT_FLOAT&gt;::Type is float.</span></div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span><span class="keyword">template</span> &lt;DataType VALUE&gt;</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno"><a class="line" href="structnn_1_1EnumToDataType.html">  142</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1EnumToDataType.html">EnumToDataType</a> {};  <span class="comment">// Specializations below</span></div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span> </div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span><span class="comment">// Template specialization for both DataTypeToEnum and EnumToDataType.</span></div>
<div class="foldopen" id="foldopen00145" data-start="" data-end="">
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno"><a class="line" href="OriginalStuff_2nn_8hpp.html#ab7cf30991ed49f035a787185466250cc">  145</a></span><span class="preprocessor">#define MATCH_TYPE_AND_ENUM(TYPE, ENUM)     \</span></div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span><span class="preprocessor">  template &lt;&gt;                               \</span></div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span><span class="preprocessor">  struct DataTypeToEnum&lt;TYPE&gt; {             \</span></div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span><span class="preprocessor">    static DataType v() { return ENUM; }    \</span></div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span><span class="preprocessor">    static constexpr DataType value = ENUM; \</span></div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span><span class="preprocessor">  };                                        \</span></div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span><span class="preprocessor">  template &lt;&gt;                               \</span></div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span><span class="preprocessor">  struct IsValidDataType&lt;TYPE&gt; {            \</span></div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span><span class="preprocessor">    static constexpr bool value = true;     \</span></div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span><span class="preprocessor">  };                                        \</span></div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span><span class="preprocessor">  template &lt;&gt;                               \</span></div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span><span class="preprocessor">  struct EnumToDataType&lt;ENUM&gt; {             \</span></div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span><span class="preprocessor">    typedef TYPE Type;                      \</span></div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span><span class="preprocessor">  }</span></div>
</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span> </div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span><a class="code hl_define" href="Parameter_8hpp.html#ab7cf30991ed49f035a787185466250cc">MATCH_TYPE_AND_ENUM</a>(<span class="keywordtype">float</span>, <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa619d8e532169cd16e25ef103f28e3213">DT_FLOAT</a>);</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span><a class="code hl_define" href="Parameter_8hpp.html#ab7cf30991ed49f035a787185466250cc">MATCH_TYPE_AND_ENUM</a>(<a class="code hl_struct" href="structEigen_1_1half.html">Eigen::half</a>, <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfae00f2994306b9bd91c2165b87d5502f3">DT_HALF</a>);</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span><a class="code hl_define" href="Parameter_8hpp.html#ab7cf30991ed49f035a787185466250cc">MATCH_TYPE_AND_ENUM</a>(<span class="keywordtype">int</span>, <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa6a6aeedaa380640cdd4933339270f7cd">DT_INT32</a>);</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span> </div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span><span class="comment">// Parameter weight and its corresponding gradient</span></div>
<div class="foldopen" id="foldopen00165" data-start="{" data-end="};">
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html">  165</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1Parameter.html">Parameter</a> {</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a583c2b74827af48d9677855299ba15cb">  166</a></span>  <a class="code hl_function" href="structnn_1_1Parameter.html#a583c2b74827af48d9677855299ba15cb">Parameter</a>(<span class="keyword">const</span> <a class="code hl_struct" href="structnn_1_1Parameter.html">Parameter</a>&amp;) = <span class="keyword">delete</span>;</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a18e03a33c68df7e4b79cb02e9d25aed8">  167</a></span>  <a class="code hl_struct" href="structnn_1_1Parameter.html">Parameter</a>&amp; <a class="code hl_function" href="structnn_1_1Parameter.html#a18e03a33c68df7e4b79cb02e9d25aed8">operator=</a>(<span class="keyword">const</span> <a class="code hl_struct" href="structnn_1_1Parameter.html">Parameter</a>&amp;) = <span class="keyword">delete</span>;</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span> </div>
<div class="foldopen" id="foldopen00169" data-start="{" data-end="}">
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#ad48cb3449bf14e55ef9ee3bbc1185040">  169</a></span>  <span class="keyword">explicit</span> <a class="code hl_function" href="structnn_1_1Parameter.html#ad48cb3449bf14e55ef9ee3bbc1185040">Parameter</a>(<a class="code hl_enumeration" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcf">DataType</a> dtype, int64_t num_element = 0)</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>      : dtype_(dtype),</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>        num_element_(num_element),</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>        data_(nullptr),</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>        grad_(nullptr) {</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>    <span class="keywordflow">if</span> (num_element) {</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>      <a class="code hl_function" href="structnn_1_1Parameter.html#a1ee1215e818b6f398934b9813c0fa03d">LazyAllocate</a>(num_element);</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>    }</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>  }</div>
</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span> </div>
<div class="foldopen" id="foldopen00179" data-start="{" data-end="}">
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#aca04f2db8d48672f0d9ffaff4cd04341">  179</a></span>  <a class="code hl_function" href="structnn_1_1Parameter.html#aca04f2db8d48672f0d9ffaff4cd04341">~Parameter</a>() {</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>    <span class="keywordflow">if</span> (data_ != <span class="keyword">nullptr</span>) {</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>      g_device.deallocate(data_);</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>    }</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>    <span class="keywordflow">if</span> (grad_ != <span class="keyword">nullptr</span>) {</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>      g_device.deallocate(grad_);</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>    }</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>  }</div>
</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span> </div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#af39913537c8c3d6b71377c3df9333b56">  188</a></span>  int64_t <a class="code hl_function" href="structnn_1_1Parameter.html#af39913537c8c3d6b71377c3df9333b56">size</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> num_element_; }</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span> </div>
<div class="foldopen" id="foldopen00190" data-start="{" data-end="}">
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a1ee1215e818b6f398934b9813c0fa03d">  190</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Parameter.html#a1ee1215e818b6f398934b9813c0fa03d">LazyAllocate</a>(<span class="keywordtype">int</span> num_element) {</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>    <span class="keywordflow">if</span> (data_ == <span class="keyword">nullptr</span>) {</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>      data_ = Allocate(dtype_, num_element);</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>      Zero(data_, dtype_, num_element);</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>      num_element_ = num_element;</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>    }</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(num_element, num_element_);</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>  }</div>
</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span> </div>
<div class="foldopen" id="foldopen00199" data-start="{" data-end="}">
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#ae5946d86c24b338dc5c0592637a97259">  199</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Parameter.html#ae5946d86c24b338dc5c0592637a97259">LazyAllocateGradient</a>() {</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>    <span class="keywordflow">if</span> (grad_ == <span class="keyword">nullptr</span>) {</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>      <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7e03ec13560fa94a8fea569960d7efc6">CHECK_GT</a>(num_element_, 0);</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>      grad_ = Allocate(dtype_, num_element_);</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>      Zero(grad_, dtype_, num_element_);</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>    }</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>  }</div>
</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span> </div>
<div class="foldopen" id="foldopen00207" data-start="{" data-end="}">
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#ad146b3bd6d2d220409ea0cf5aebfe2eb">  207</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Parameter.html#ad146b3bd6d2d220409ea0cf5aebfe2eb">ZeroData</a>() {</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>    <span class="keywordflow">if</span> (data_ != <span class="keyword">nullptr</span>) {</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>      Zero(data_, dtype_, num_element_);</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>    }</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>  }</div>
</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span> </div>
<div class="foldopen" id="foldopen00213" data-start="{" data-end="}">
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a52db062016881a2cb90535351c4377ef">  213</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Parameter.html#a52db062016881a2cb90535351c4377ef">ZeroGrad</a>() {</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>    <span class="keywordflow">if</span> (grad_ != <span class="keyword">nullptr</span>) {</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>      Zero(grad_, dtype_, num_element_);</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>    }</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>  }</div>
</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span> </div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00220" data-start="{" data-end="}">
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">  220</a></span>  T* <a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>    <span class="keywordflow">return</span> <span class="keyword">static_cast&lt;</span>T*<span class="keyword">&gt;</span>(data_);</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>  }</div>
</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span> </div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00225" data-start="{" data-end="}">
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">  225</a></span>  T* <a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>    <span class="keywordflow">return</span> <span class="keyword">static_cast&lt;</span>T*<span class="keyword">&gt;</span>(grad_);</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>  }</div>
</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span> </div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00230" data-start="{" data-end="}">
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#abe781e9cb2ab94df0e45ce4adf20d56d">  230</a></span>  <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;T&gt;</a> <a class="code hl_function" href="structnn_1_1Parameter.html#abe781e9cb2ab94df0e45ce4adf20d56d">span</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(num_element_)};</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>  }</div>
</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span> </div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00236" data-start="{" data-end="}">
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a26d35841294de83ed2f9a64525d1420b">  236</a></span>  <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;T&gt;</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a26d35841294de83ed2f9a64525d1420b">span_grad</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(num_element_)};</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>  }</div>
</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span> </div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00242" data-start="{" data-end="}">
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a6f0e1ddc221a505c43c7abf5bcf439ee">  242</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a6f0e1ddc221a505c43c7abf5bcf439ee">flat</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), num_element_};</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>  }</div>
</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00247" data-start="{" data-end="}">
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#ac0ee4086c327b580089e3df17177c295">  247</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> <a class="code hl_function" href="structnn_1_1Parameter.html#ac0ee4086c327b580089e3df17177c295">const_flat</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), num_element_};</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>  }</div>
</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span> </div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00253" data-start="{" data-end="}">
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a57425fbc922f81c2d9ef81287c29b24e">  253</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a57425fbc922f81c2d9ef81287c29b24e">matrix</a>(<span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(rows * cols, num_element_);</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), rows, cols};</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>  }</div>
</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00259" data-start="{" data-end="}">
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#ad9ef295d080c627b955acbf5b25b78a9">  259</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> <a class="code hl_function" href="structnn_1_1Parameter.html#ad9ef295d080c627b955acbf5b25b78a9">const_matrix</a>(<span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(rows * cols, num_element_);</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), rows, cols};</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>  }</div>
</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span> </div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00266" data-start="{" data-end="}">
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a0225855097608608bd9d4e1df866126c">  266</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 3&gt;::Tensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a0225855097608608bd9d4e1df866126c">tensor_3d</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1, <span class="keywordtype">int</span> dim2)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2, num_element_);</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), dim0, dim1, dim2};</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>  }</div>
</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00272" data-start="{" data-end="}">
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a7c03f7343425f14757e8921a2cc5d13d">  272</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 3&gt;::ConstTensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a7c03f7343425f14757e8921a2cc5d13d">const_tensor_3d</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1,</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>                                                     <span class="keywordtype">int</span> dim2)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2, num_element_);</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), dim0, dim1, dim2};</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>  }</div>
</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span> </div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00280" data-start="{" data-end="}">
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a96fd7a8f8ff1890afc82c16006105642">  280</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 4&gt;::Tensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a96fd7a8f8ff1890afc82c16006105642">tensor_4d</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1, <span class="keywordtype">int</span> dim2,</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>                                          <span class="keywordtype">int</span> dim3)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2 * dim3, num_element_);</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), dim0, dim1, dim2, dim3};</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>  }</div>
</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00287" data-start="{" data-end="}">
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a2fe94f0c8a72286208dbd447419f7fd0">  287</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 4&gt;::ConstTensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a2fe94f0c8a72286208dbd447419f7fd0">const_tensor_4d</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1,</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>                                                     <span class="keywordtype">int</span> dim2, <span class="keywordtype">int</span> dim3)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2 * dim3, num_element_);</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data&lt;T&gt;</a>(), dim0, dim1, dim2, dim3};</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>  }</div>
</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span> </div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00295" data-start="{" data-end="}">
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#adc5d7e335fd359c4abaa49579c66bd72">  295</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> <a class="code hl_function" href="structnn_1_1Parameter.html#adc5d7e335fd359c4abaa49579c66bd72">flat_grad</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), num_element_};</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>  }</div>
</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00300" data-start="{" data-end="}">
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a6d0ae2b005bfc890d7d8b72798dcc43a">  300</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a6d0ae2b005bfc890d7d8b72798dcc43a">const_flat_grad</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), num_element_};</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>  }</div>
</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span> </div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00306" data-start="{" data-end="}">
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a9b7a7795983465be2eb5cb5546cd63a3">  306</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a9b7a7795983465be2eb5cb5546cd63a3">matrix_grad</a>(<span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(rows * cols, num_element_);</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), rows, cols};</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>  }</div>
</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00312" data-start="{" data-end="}">
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a1510411a8f4221a6e163896c7e586f90">  312</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a1510411a8f4221a6e163896c7e586f90">const_matrix_grad</a>(<span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(rows * cols, num_element_);</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), rows, cols};</div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>  }</div>
</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span> </div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00319" data-start="{" data-end="}">
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a83ee4857383ef5f5e62de7529498d43e">  319</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 3&gt;::Tensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a83ee4857383ef5f5e62de7529498d43e">tensor_3d_grad</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1,</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>                                               <span class="keywordtype">int</span> dim2)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2, num_element_);</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), dim0, dim1, dim2};</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>  }</div>
</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00326" data-start="{" data-end="}">
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#ae9da6b86774d2ff46dfbd89c432c12e4">  326</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 3&gt;::ConstTensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#ae9da6b86774d2ff46dfbd89c432c12e4">const_tensor_3d_grad</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1,</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>                                                          <span class="keywordtype">int</span> dim2)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2, num_element_);</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), dim0, dim1, dim2};</div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span>  }</div>
</div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span> </div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00334" data-start="{" data-end="}">
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#ad1e84918801072e188a3c683f668e5cf">  334</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 4&gt;::Tensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#ad1e84918801072e188a3c683f668e5cf">tensor_4d_grad</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1, <span class="keywordtype">int</span> dim2,</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span>                                               <span class="keywordtype">int</span> dim3)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2 * dim3, num_element_);</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), dim0, dim1, dim2, dim3};</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>  }</div>
</div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span> </div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00342" data-start="{" data-end="}">
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno"><a class="line" href="structnn_1_1Parameter.html#a64181c4853cb79169680bbf4bce05f3d">  342</a></span>  <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T, 4&gt;::ConstTensor</a> <a class="code hl_function" href="structnn_1_1Parameter.html#a64181c4853cb79169680bbf4bce05f3d">const_tensor_4d_grad</a>(<span class="keywordtype">int</span> dim0, <span class="keywordtype">int</span> dim1,</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>                                                          <span class="keywordtype">int</span> dim2,</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>                                                          <span class="keywordtype">int</span> dim3)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>, dtype_);</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(dim0 * dim1 * dim2 * dim3, num_element_);</div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>    <span class="keywordflow">return</span> {<a class="code hl_function" href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">grad&lt;T&gt;</a>(), dim0, dim1, dim2, dim3};</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>  }</div>
</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span> </div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span> <span class="keyword">private</span>:</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>  <span class="keyword">static</span> <span class="keywordtype">void</span>* Allocate(<a class="code hl_enumeration" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcf">DataType</a> dtype, int64_t num_element) {</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>    <span class="keywordflow">if</span> (dtype == <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa619d8e532169cd16e25ef103f28e3213">DT_FLOAT</a>) {</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>      <span class="keywordflow">return</span> g_device.allocate(<span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * num_element);</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (dtype == <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfae00f2994306b9bd91c2165b87d5502f3">DT_HALF</a>) {</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>      <span class="keywordflow">return</span> g_device.allocate(<span class="keyword">sizeof</span>(<a class="code hl_struct" href="structEigen_1_1half.html">Eigen::half</a>) * num_element);</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>      <span class="keywordflow">throw</span> std::invalid_argument(<span class="stringliteral">&quot;invalid data type: &quot;</span> +</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>                                  std::to_string(dtype));</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>    }</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>  }</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span> </div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>  <span class="keyword">static</span> <span class="keywordtype">void</span> Zero(<span class="keywordtype">void</span>* <a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data</a>, <a class="code hl_enumeration" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcf">DataType</a> dtype, int64_t num_element) {</div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>    <span class="keywordflow">if</span> (dtype == <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa619d8e532169cd16e25ef103f28e3213">DT_FLOAT</a>) {</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>      g_device.memset(<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data</a>, 0, <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * num_element);</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (dtype == <a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfae00f2994306b9bd91c2165b87d5502f3">DT_HALF</a>) {</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>      g_device.memset(<a class="code hl_function" href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">data</a>, 0, <span class="keyword">sizeof</span>(<a class="code hl_struct" href="structEigen_1_1half.html">Eigen::half</a>) * num_element);</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>      <span class="keywordflow">throw</span> std::invalid_argument(<span class="stringliteral">&quot;invalid data type: &quot;</span> +</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>                                  std::to_string(dtype));</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>    }</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>  }</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span> </div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span>  <a class="code hl_enumeration" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcf">DataType</a> dtype_;</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>  <a class="code hl_typedef" href="namespaceEigen_1_1numext.html#a26035668345422b5f30be2124b0b6f6e">int64_t</a> num_element_;</div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>  <span class="keywordtype">void</span>* data_;</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>  <span class="keywordtype">void</span>* grad_;</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>};</div>
</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span> </div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span><span class="keyword">using </span><a class="code hl_typedef" href="namespacenn.html#a15e2232b24a304936a0f3d6452ab7095">Activation</a> = Parameter;</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span> </div>
<div class="foldopen" id="foldopen00381" data-start="{" data-end="};">
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno"><a class="line" href="structnn_1_1MatMul.html">  381</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1MatMul.html">MatMul</a> {</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1MatMul.html#a64937ece43bd2e55440ff29d940cdb9a">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span> </div>
<div class="foldopen" id="foldopen00384" data-start="{" data-end="}">
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno"><a class="line" href="structnn_1_1MatMul.html#a8d05ee55fe5c544993b4371333300e78">  384</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1MatMul.html#a8d05ee55fe5c544993b4371333300e78">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x1,</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>                      <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x2,</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>                      <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> y, <a class="code hl_typedef" href="structnn_1_1MatMul.html#a64937ece43bd2e55440ff29d940cdb9a">T</a> scale = 1.0f) {</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>    <span class="comment">// x: [M, N], x2: [N, K], y: [M, K]</span></div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x1.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), y.dimension(0));</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x1.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1), x2.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x2.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1), y.dimension(1));</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span> </div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>    <span class="comment">// y = x1 * x2</span></div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>    <span class="comment">//    y.noalias() = x1 * x2;</span></div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::IndexPair&lt;int&gt;</a>, 1&gt; product_dims = {</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>        <a class="code hl_struct" href="structEigen_1_1IndexPair.html">Eigen::IndexPair&lt;int&gt;</a>(1, 0)};</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>    y.device(g_device) = x1.contract(x2, product_dims) * scale;</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>  }</div>
</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span> </div>
<div class="foldopen" id="foldopen00399" data-start="{" data-end="}">
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno"><a class="line" href="structnn_1_1MatMul.html#aeb87efe916cb0309e67f3957ba6628a1">  399</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1MatMul.html#aeb87efe916cb0309e67f3957ba6628a1">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x1,</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x2,</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> y_grad,</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> x1_grad,</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> x2_grad, <a class="code hl_typedef" href="structnn_1_1MatMul.html#a64937ece43bd2e55440ff29d940cdb9a">T</a> scale = 1.0) {</div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>    <span class="comment">// input:</span></div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>    <span class="comment">// x1: [M, N], x2:[N, K]</span></div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>    <span class="comment">// y_grad: [M, K]</span></div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>    <span class="comment">//</span></div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>    <span class="comment">// output:</span></div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span>    <span class="comment">// x1_grad: [M, N], x2_grad: [N, K]</span></div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>    <span class="keywordtype">int</span> M = x1.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> = x1.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1), K = x2.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(M == y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; M == x1_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(<a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> == x2.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; <a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> == x1_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1) &amp;&amp;</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>          <a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> == x2_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(K == y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1) &amp;&amp; K == x2_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span> </div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>    <span class="comment">// x1_grad = dL/dy * dy/dx1</span></div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>    <span class="comment">//        = y_grad(M, K) * x2^T (K, N)</span></div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>    <span class="comment">//        = [M, N]</span></div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::IndexPair&lt;int&gt;</a>, 1&gt; product_dims = {</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>        <a class="code hl_struct" href="structEigen_1_1IndexPair.html">Eigen::IndexPair&lt;int&gt;</a>(1, 1)};</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>    x1_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += y_grad.contract(x2, product_dims) * scale;</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span> </div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>    <span class="comment">// x2_grad = dL/dy * dy/dx2</span></div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>    <span class="comment">//        = x1^T(N, M) * y_grad(M, K)</span></div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>    <span class="comment">//        = [N, K]</span></div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span> </div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::IndexPair&lt;int&gt;</a>, 1&gt; product_dims2 = {</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>        <a class="code hl_struct" href="structEigen_1_1IndexPair.html">Eigen::IndexPair&lt;int&gt;</a>(0, 0)};</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>    x2_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += x1.contract(y_grad, product_dims2) * scale;</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>  }</div>
</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>};</div>
</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span> </div>
<div class="foldopen" id="foldopen00433" data-start="{" data-end="};">
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno"><a class="line" href="structnn_1_1Residual.html">  433</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1Residual.html">Residual</a> {</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1Residual.html#a6058419c871cad6d7ec56982369bc57a">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span> </div>
<div class="foldopen" id="foldopen00436" data-start="{" data-end="}">
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno"><a class="line" href="structnn_1_1Residual.html#a4891550c91057f4f56dd81242f62893d">  436</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Residual.html#a4891550c91057f4f56dd81242f62893d">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> x,</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>                      <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> Fx,</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>                      <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> Hx) {</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>    <span class="keywordtype">int</span> <a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> = x.size();</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(<a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> == Fx.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>() &amp;&amp; <a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> == Hx.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span> </div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>    <span class="comment">// H(x) = x + F(x) -&gt; F(x) = H(x) - x</span></div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>    Hx.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) = x + Fx;</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>  }</div>
</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span> </div>
<div class="foldopen" id="foldopen00446" data-start="{" data-end="}">
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno"><a class="line" href="structnn_1_1Residual.html#a99d49a6ebe5268051e6de48f423e2a43">  446</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Residual.html#a99d49a6ebe5268051e6de48f423e2a43">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> Hx_grad,</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> x_grad,</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> Fx_grad) {</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>    <span class="keywordtype">int</span> <a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> = Hx_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>();</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(<a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> == x_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>() &amp;&amp; <a class="code hl_variable" href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a> == Fx_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span> </div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>    x_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += Hx_grad;</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>    Fx_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += Hx_grad;</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>  }</div>
</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>};</div>
</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span> </div>
<div class="foldopen" id="foldopen00457" data-start="{" data-end="};">
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno"><a class="line" href="structnn_1_1Linear.html">  457</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1Linear.html">Linear</a> {</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span> </div>
<div class="foldopen" id="foldopen00460" data-start="{" data-end="}">
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno"><a class="line" href="structnn_1_1Linear.html#a34d599cf91de5e85d30162cecab1201d">  460</a></span>  <a class="code hl_function" href="structnn_1_1Linear.html#a34d599cf91de5e85d30162cecab1201d">Linear</a>(<span class="keywordtype">int</span> in_features, <span class="keywordtype">int</span> out_features, <span class="keywordtype">bool</span> bias = <span class="keyword">true</span>)</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>      : <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>(in_features),</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>        <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>(out_features),</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>        <a class="code hl_variable" href="structnn_1_1Linear.html#a72bd5097d6212d9c40124b2a9112aea7">has_bias_</a>(bias) {</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>    <span class="keyword">auto</span> dtype = <a class="code hl_struct" href="structnn_1_1DataTypeToEnum.html">DataTypeToEnum&lt;T&gt;::value</a>;</div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>    <a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a> = std::make_unique&lt;Parameter&gt;(dtype, out_features * in_features);</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>    <a class="code hl_function" href="namespacenn.html#a5268109b8c87089a840f743713f8781f">KaimingUniformFill</a>(<a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a>-&gt;span&lt;<a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a>&gt;(), in_features);</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>    <span class="keywordflow">if</span> (bias) {</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>      <a class="code hl_variable" href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">bias_</a> = std::make_unique&lt;Parameter&gt;(dtype, out_features);</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span>      <span class="keyword">const</span> <span class="keywordtype">float</span> bound = 1.0f / std::sqrt(<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(in_features));</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>      <a class="code hl_function" href="namespacenn.html#aa7f7fc1fcad89e0745dbae4bfad4d356">UniformFill</a>(<a class="code hl_variable" href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">bias_</a>-&gt;span&lt;<a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a>&gt;(), -bound, bound);</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>    }</div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span>  }</div>
</div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span> </div>
<div class="foldopen" id="foldopen00474" data-start="{" data-end="}">
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno"><a class="line" href="structnn_1_1Linear.html#a64e6ffe3fbc3c76826b715609a105b22">  474</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Linear.html#a64e6ffe3fbc3c76826b715609a105b22">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x,</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>               <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> y)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>    <span class="comment">// x: [B, in_features], y: [B, out_features]</span></div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(1), <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>);</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(y.dimension(1), <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>);</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(0), y.dimension(0));</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>    <span class="keywordtype">int</span> B = x.dimension(0);</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span> </div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>    <span class="keyword">auto</span> weight = <a class="code hl_function" href="OriginalStuff_2tensor__util_8hpp.html#a30c79fba785f603a86fa02252305fbed">MakeMatrix</a>(<a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a>-&gt;data&lt;<a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a>&gt;(), <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>, <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>);</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>    <span class="comment">// y = x * w^T + b</span></div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::IndexPair&lt;int&gt;</a>, 1&gt; product_dims = {</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>        <a class="code hl_struct" href="structEigen_1_1IndexPair.html">Eigen::IndexPair&lt;int&gt;</a>(1, 1)};</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="structnn_1_1Linear.html#a72bd5097d6212d9c40124b2a9112aea7">has_bias_</a>) {</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>      <span class="keyword">auto</span> bias = <a class="code hl_function" href="OriginalStuff_2tensor__util_8hpp.html#a9a087a9b5b6b2f4a06af705501667b9b">MakeFlat</a>(<a class="code hl_variable" href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">bias_</a>-&gt;data&lt;<a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a>&gt;(), <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>);</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>      <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;int, 2&gt;</a> batch_by_one = {B, 1},</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>                           one_by_out = {1, <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>};</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>      y.device(g_device) = x.contract(weight, product_dims) +</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>                           bias.reshape(one_by_out).broadcast(batch_by_one);</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>      y.device(g_device) = x.contract(weight, product_dims);</div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>    }</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>  }</div>
</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span> </div>
<div class="foldopen" id="foldopen00497" data-start="{" data-end="}">
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno"><a class="line" href="structnn_1_1Linear.html#adc5b2d2b9d62d9dca412db85ee72d7e1">  497</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Linear.html#adc5b2d2b9d62d9dca412db85ee72d7e1">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x,</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>                <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> y_grad,</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>                <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> x_grad) {</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>    <span class="comment">// x: [B, in_features], y_grad: [B, out_features], x_grad: [B, in_features]</span></div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(1), <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>);</div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1), <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>);</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(0), y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(0), x_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span> </div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>    <span class="comment">// Lazily allocate the memory for gradients</span></div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>    <a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a>-&gt;LazyAllocateGradient();</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>    <span class="keyword">auto</span> weight = <a class="code hl_function" href="OriginalStuff_2tensor__util_8hpp.html#a30c79fba785f603a86fa02252305fbed">MakeMatrix</a>(<a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a>-&gt;data&lt;<a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a>&gt;(), <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>, <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>);</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>    <span class="keyword">auto</span> weight_grad =</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>        <a class="code hl_function" href="OriginalStuff_2tensor__util_8hpp.html#a30c79fba785f603a86fa02252305fbed">MakeMatrix</a>(<a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a>-&gt;grad&lt;<a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a>&gt;(), <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>, <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>);</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span> </div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>    <span class="comment">// x_grad = dL/dy * dy/dx</span></div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>    <span class="comment">//        = y_grad(B, out_features) * W(out_features, in_features)</span></div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>    <span class="comment">//        = [B, in_features]</span></div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::IndexPair&lt;int&gt;</a>, 1&gt; product_dims = {</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>        <a class="code hl_struct" href="structEigen_1_1IndexPair.html">Eigen::IndexPair&lt;int&gt;</a>(1, 0)};</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>    x_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += y_grad.contract(weight, product_dims);</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span> </div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>    <span class="comment">// w_grad = dL/dy * dy/dw</span></div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>    <span class="comment">//        = y_grad^T(out_features, B) * x(B, in_features)</span></div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>    <span class="comment">//        = [out_features, in_features]</span></div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::IndexPair&lt;int&gt;</a>, 1&gt; product_dims2 = {</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>        <a class="code hl_struct" href="structEigen_1_1IndexPair.html">Eigen::IndexPair&lt;int&gt;</a>(0, 0)};</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>    weight_grad.device(g_device) += y_grad.contract(x, product_dims2);</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span> </div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="structnn_1_1Linear.html#a72bd5097d6212d9c40124b2a9112aea7">has_bias_</a>) {</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>      <span class="comment">// b_grad = dL/dy * dy/db</span></div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>      <span class="comment">//        = \sum_i^(B)(y_grad(B, out_features))</span></div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>      <span class="comment">//        = [out_features,]</span></div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span>      <a class="code hl_variable" href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">bias_</a>-&gt;LazyAllocateGradient();</div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>      <span class="keyword">auto</span> bias_grad = <a class="code hl_function" href="OriginalStuff_2tensor__util_8hpp.html#a9a087a9b5b6b2f4a06af705501667b9b">MakeFlat</a>(<a class="code hl_variable" href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">bias_</a>-&gt;grad&lt;<a class="code hl_typedef" href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">T</a>&gt;(), <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>);</div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span>      <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 1&gt;</a> along_batch = {0};</div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>      bias_grad.device(g_device) = y_grad.sum(along_batch);</div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>    }</div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>  }</div>
</div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span> </div>
<div class="foldopen" id="foldopen00537" data-start="{" data-end="}">
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno"><a class="line" href="structnn_1_1Linear.html#a409875da04ee814f1da7847a261b0a8a">  537</a></span>  <span class="keywordtype">size_t</span> <a class="code hl_function" href="structnn_1_1Linear.html#a409875da04ee814f1da7847a261b0a8a">NumParameters</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>    <span class="keywordtype">size_t</span> num_parameters = <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a> * <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>;</div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="structnn_1_1Linear.html#a72bd5097d6212d9c40124b2a9112aea7">has_bias_</a>) {</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span>      num_parameters += <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>;</div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>    }</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span> </div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>    <span class="keywordflow">return</span> num_parameters;</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>  }</div>
</div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span> </div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno"><a class="line" href="structnn_1_1Linear.html#a604a0a510c6eed24be8b31b6d1e131b1">  546</a></span>  <span class="keywordtype">size_t</span> <a class="code hl_function" href="structnn_1_1Linear.html#a604a0a510c6eed24be8b31b6d1e131b1">NumActivations</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 0; }</div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span> </div>
<div class="foldopen" id="foldopen00548" data-start="{" data-end="}">
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno"><a class="line" href="structnn_1_1Linear.html#a2f1e0f7cef394d2a5f3988ade39de320">  548</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Linear.html#a2f1e0f7cef394d2a5f3988ade39de320">Parameters</a>(std::vector&lt;Parameter*&gt;* parameters)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span>    parameters-&gt;push_back(<a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a>.get());</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="structnn_1_1Linear.html#a72bd5097d6212d9c40124b2a9112aea7">has_bias_</a>) {</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span>      parameters-&gt;push_back(<a class="code hl_variable" href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">bias_</a>.get());</div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>    }</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>  }</div>
</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span> </div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="structnn_1_1Linear.html#a72bd5097d6212d9c40124b2a9112aea7">has_bias_</a>;</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">in_features_</a>;</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">out_features_</a>;</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>  std::unique_ptr&lt;Parameter&gt; <a class="code hl_variable" href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">weight_</a>;  <span class="comment">// out_features x in_features</span></div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>  std::unique_ptr&lt;Parameter&gt; <a class="code hl_variable" href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">bias_</a>;    <span class="comment">// out_features</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span>};</div>
</div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span> </div>
<div class="foldopen" id="foldopen00562" data-start="{" data-end="};">
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno"><a class="line" href="structnn_1_1Embedding.html">  562</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1Embedding.html">Embedding</a> {</div>
<div class="foldopen" id="foldopen00563" data-start="{" data-end="}">
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno"><a class="line" href="structnn_1_1Embedding.html#a63bb11f840116115c042f99771853944">  563</a></span>  <a class="code hl_function" href="structnn_1_1Embedding.html#a63bb11f840116115c042f99771853944">Embedding</a>(<span class="keywordtype">int</span> num_embeddings, <span class="keywordtype">int</span> embedding_dim)</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>      : <a class="code hl_variable" href="structnn_1_1Embedding.html#a9aa76d7d0487450a2ca01c185b0375c1">num_embeddings_</a>(num_embeddings), <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>(embedding_dim) {</div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>    <a class="code hl_variable" href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">weight_</a> =</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span>        std::make_unique&lt;Parameter&gt;(<a class="code hl_enumvalue" href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa619d8e532169cd16e25ef103f28e3213">DT_FLOAT</a>, num_embeddings * embedding_dim);</div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>    <a class="code hl_function" href="namespacenn.html#a7a0bfd75fc17c62ba9e681cd3d346efc">NormalFill</a>(<a class="code hl_variable" href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">weight_</a>-&gt;span&lt;<span class="keywordtype">float</span>&gt;());</div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>  }</div>
</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span> </div>
<div class="foldopen" id="foldopen00570" data-start="{" data-end="}">
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno"><a class="line" href="structnn_1_1Embedding.html#ae46671667b089b91f58428338b7097a4">  570</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Embedding.html#ae46671667b089b91f58428338b7097a4">Forward</a>(<a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> idx, <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;float&gt;</a> embedding)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(embedding.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(), idx.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>() * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>);</div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> &lt; idx.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(); ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>) {</div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span>      <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a4bd2e815ca2f702a4b6aa744b1ff3b82">CHECK_LT</a>(idx[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>], <a class="code hl_variable" href="structnn_1_1Embedding.html#a9aa76d7d0487450a2ca01c185b0375c1">num_embeddings_</a>);</div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span>      <span class="keywordtype">void</span>* dst = embedding.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>() + <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>;</div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span>      <span class="keywordtype">void</span>* src = <a class="code hl_variable" href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">weight_</a>-&gt;data&lt;<span class="keywordtype">float</span>&gt;() + idx[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>] * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>;</div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span>      g_device.memcpy(dst, src, <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>);</div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span>    }</div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span>  }</div>
</div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span> </div>
<div class="foldopen" id="foldopen00580" data-start="{" data-end="}">
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno"><a class="line" href="structnn_1_1Embedding.html#a427a7f4f7e77b6904e6fa19b373ebc34">  580</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Embedding.html#a427a7f4f7e77b6904e6fa19b373ebc34">Backward</a>(<a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> idx,</div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span>                <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const float&gt;</a> grad_embedding) {</div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(grad_embedding.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(), idx.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>() * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>);</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span> </div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>    <span class="comment">// Lazily allocate the memory for gradients</span></div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span>    <a class="code hl_variable" href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">weight_</a>-&gt;LazyAllocateGradient();</div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> &lt; idx.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(); ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>) {</div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span>      <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a4bd2e815ca2f702a4b6aa744b1ff3b82">CHECK_LT</a>(idx[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>], <a class="code hl_variable" href="structnn_1_1Embedding.html#a9aa76d7d0487450a2ca01c185b0375c1">num_embeddings_</a>);</div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span>      <span class="keyword">const</span> <span class="keywordtype">float</span>* g = grad_embedding.<a class="code hl_function" href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">data</a>() + <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>;</div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span>      <span class="keywordtype">float</span>* grad = <a class="code hl_variable" href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">weight_</a>-&gt;grad&lt;<span class="keywordtype">float</span>&gt;() + idx[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>] * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>;</div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span>      <span class="keyword">auto</span> g_1d = <a class="code hl_typedef" href="structTTypes.html#aa53f19202b54ddd0fe543e2e7f771caf">TTypes&lt;float&gt;::UnalignedConstFlat</a>(g, <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>);</div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span>      <span class="keyword">auto</span> grad_1d = <a class="code hl_typedef" href="structTTypes.html#aea634ba279401433e58c5e59b008cf36">TTypes&lt;float&gt;::UnalignedFlat</a>(grad, <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>);</div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span>      grad_1d.device(g_device) += g_1d;</div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>    }</div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span>  }</div>
</div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span> </div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno"><a class="line" href="structnn_1_1Embedding.html#a17a1666754ba09e03c9073abc89e27e8">  596</a></span>  <span class="keywordtype">size_t</span> <a class="code hl_function" href="structnn_1_1Embedding.html#a17a1666754ba09e03c9073abc89e27e8">NumParameters</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code hl_variable" href="structnn_1_1Embedding.html#a9aa76d7d0487450a2ca01c185b0375c1">num_embeddings_</a> * <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>; }</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span> </div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno"><a class="line" href="structnn_1_1Embedding.html#a0836507be6dea19c0289e580e2fb8973">  598</a></span>  <span class="keywordtype">size_t</span> <a class="code hl_function" href="structnn_1_1Embedding.html#a0836507be6dea19c0289e580e2fb8973">NumActivations</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 0; }</div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span> </div>
<div class="foldopen" id="foldopen00600" data-start="{" data-end="}">
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno"><a class="line" href="structnn_1_1Embedding.html#a8669a3a9dadd00830d3d1d0b48a37789">  600</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Embedding.html#a8669a3a9dadd00830d3d1d0b48a37789">Parameters</a>(std::vector&lt;Parameter*&gt;* parameters)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span>    parameters-&gt;push_back(<a class="code hl_variable" href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">weight_</a>.get());</div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span>  }</div>
</div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span> </div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="structnn_1_1Embedding.html#a9aa76d7d0487450a2ca01c185b0375c1">num_embeddings_</a>;</div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">embedding_dim_</a>;</div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span>  std::unique_ptr&lt;Parameter&gt; <a class="code hl_variable" href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">weight_</a>;</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span>};</div>
</div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span> </div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span> </div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span><span class="comment">// Careful there are a few versions of GeLU, this one is the exact one used by</span></div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span><span class="comment">// OpenAI</span></div>
<div class="foldopen" id="foldopen00612" data-start="{" data-end="};">
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno"><a class="line" href="structnn_1_1NewGELU.html">  612</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1NewGELU.html">NewGELU</a> {</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1NewGELU.html#aea252245f5f7a07d0b5dcb8156e14a03">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span> </div>
<div class="foldopen" id="foldopen00615" data-start="{" data-end="}">
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno"><a class="line" href="structnn_1_1NewGELU.html#aa83faf7441c0ebe6c33fd3f7610eb1dc">  615</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1NewGELU.html#aa83faf7441c0ebe6c33fd3f7610eb1dc">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> x,</div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span>                      <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> y) {</div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.size(), y.size());</div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> sqrt_2_over_pi = std::sqrt(M_2_PI);</div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span> </div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span>    <span class="comment">// y = 0.5 * x * (1.0 + tanh[sqrt(2/pi) * (x + 0.044715 * x^3)])</span></div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>    <span class="keywordtype">float</span> coeff = 0.044715f;</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span>    y.device(g_device) =</div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span>        0.5 * x * (1.0 + ((sqrt_2_over_pi * (x + coeff * x * x * x)).tanh()));</div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>  }</div>
</div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span> </div>
<div class="foldopen" id="foldopen00626" data-start="{" data-end="}">
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno"><a class="line" href="structnn_1_1NewGELU.html#a61bfcf96b22838809e7ed1c217df351f">  626</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1NewGELU.html#a61bfcf96b22838809e7ed1c217df351f">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> x,</div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstFlat</a> y_grad,</div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> x_grad) {</div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.size(), y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.size(), x_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span> </div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span>    <span class="comment">// dL/dx = dL/dy * dy/dx</span></div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span>    <span class="comment">//       = dL/dy * [ 0.5 * (1.0 + tanh[sqrt(2/pi) * (x + 0.044715 * x^3)])</span></div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span>    <span class="comment">//                 + 0.5 * x * (1 - (tanh[sqrt(2/pi) * (x + 0.044715 *</span></div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span>    <span class="comment">//                 x^3)])^2</span></div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span>    <span class="comment">//                           *  (sqrt(2/pi) * (1 + 0.044715 * 3 * x^2))</span></div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span>    <span class="comment">//                             )</span></div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span>    <span class="comment">//                 ]</span></div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span> </div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> sqrt_2_over_pi = std::sqrt(M_2_PI);</div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span>    <span class="keywordtype">float</span> coeff = 0.044715f;</div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>    <span class="keyword">auto</span> <a class="code hl_function" href="eigen_2Eigen_2src_2plugins_2ArrayCwiseUnaryOps_8h.html#ad816d4a0c05f21e660e91e9febb1b900">cube</a> = coeff * x * x * x;</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span>    <span class="keyword">auto</span> tanh_arg = sqrt_2_over_pi * (x + <a class="code hl_function" href="eigen_2Eigen_2src_2plugins_2ArrayCwiseUnaryOps_8h.html#ad816d4a0c05f21e660e91e9febb1b900">cube</a>);</div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span>    <span class="keyword">auto</span> tanh_out = tanh_arg.tanh();</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>    <span class="keyword">auto</span> dydx = 0.5f * (1.0f + tanh_out) +</div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span>                0.5f * x * (1.0f - tanh_out * tanh_out) *</div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span>                    (sqrt_2_over_pi * (1.0f + 3.0f * coeff * x * x));</div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span>    x_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += y_grad * dydx;</div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span>  }</div>
</div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span>};</div>
</div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span> </div>
<div class="foldopen" id="foldopen00652" data-start="{" data-end="};">
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno"><a class="line" href="structnn_1_1Softmax.html">  652</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1Softmax.html">Softmax</a> {</div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1Softmax.html#af7722532871a3341255166920486e0aa">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span> </div>
<div class="foldopen" id="foldopen00655" data-start="{" data-end="}">
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno"><a class="line" href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">  655</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x,</div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>                      <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> y) {</div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span>    <span class="comment">// x: [B, D], y: [B, D]</span></div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(0), y.dimension(0));</div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(1), y.dimension(1));</div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span> </div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span>    <span class="keywordtype">int</span> batch_size = x.dimension(0), num_class = x.dimension(1);</div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 1&gt;</a> along_class = {1};</div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> batch_by_one = {batch_size, 1};</div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> one_by_class = {1, num_class};</div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span> </div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span>    y.device(g_device) = (x - x.maximum(along_class)</div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span>                                  .eval()</div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span>                                  .reshape(batch_by_one)</div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span>                                  .broadcast(one_by_class))</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>                             .exp();</div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span>    y.device(g_device) = y * y.sum(along_class)</div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span>                                 .inverse()</div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span>                                 .eval()</div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span>                                 .reshape(batch_by_one)</div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span>                                 .broadcast(one_by_class);</div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span>  }</div>
</div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span> </div>
<div class="foldopen" id="foldopen00678" data-start="{" data-end="}">
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno"><a class="line" href="structnn_1_1Softmax.html#a1552ecc513a69adec694e31a57bc926d">  678</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Softmax.html#a1552ecc513a69adec694e31a57bc926d">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> y,</div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> y_grad,</div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> x_grad) {</div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span>    <span class="comment">// y:[B, D], y_grad: [B, D], x_grad: [B, D]</span></div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span>    <span class="keywordtype">int</span> B = y.dimension(0), D = y.dimension(1);</div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; B == x_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(D == y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1) &amp;&amp; D == x_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno">  685</span> </div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span>    <span class="comment">// Using alternative formula:</span></div>
<div class="line"><a id="l00687" name="l00687"></a><span class="lineno">  687</span>    <span class="comment">// dL/dx = dL/dy * y - sum(dL/dy * y) * y</span></div>
<div class="line"><a id="l00688" name="l00688"></a><span class="lineno">  688</span>    <span class="comment">//    = (dL/dy - sum(dL/dy * y)) * y</span></div>
<div class="line"><a id="l00689" name="l00689"></a><span class="lineno">  689</span>    <span class="keywordtype">int</span> batch_size = y.dimension(0), num_class = y.dimension(1);</div>
<div class="line"><a id="l00690" name="l00690"></a><span class="lineno">  690</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> batch_by_one = {batch_size, 1};</div>
<div class="line"><a id="l00691" name="l00691"></a><span class="lineno">  691</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> one_by_class = {1, num_class};</div>
<div class="line"><a id="l00692" name="l00692"></a><span class="lineno">  692</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 1&gt;</a> along_class = {1};</div>
<div class="line"><a id="l00693" name="l00693"></a><span class="lineno">  693</span>    <span class="keyword">auto</span> dyy = y_grad * y;</div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span>    <span class="keyword">auto</span> sum = dyy.sum(along_class).reshape(batch_by_one);</div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span>    <span class="keyword">auto</span> sub = y_grad - sum.broadcast(one_by_class);</div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span>    x_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += sub * y;</div>
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno">  697</span> </div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span>    <span class="comment">/*</span></div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span><span class="comment">    // dy_j / dx_i = S_i(1 - S_j) for i==j</span></div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span><span class="comment">    //             = -S_j*S_i     for i!=j</span></div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span><span class="comment">    // dL/dx_i = \sum_j dL/dy_j * dy_j / dx_i</span></div>
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno">  702</span><span class="comment">    auto fn = [D, &amp;x_grad, &amp;y_grad, &amp;y](int begin, int end) {</span></div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span><span class="comment">      for (int b = begin; b &lt; end; ++b) {</span></div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span><span class="comment">        float* x_grad_b = x_grad.data() + b * D;</span></div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span><span class="comment">        float* y_grad_b = y_grad.data() + b * D;</span></div>
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno">  706</span><span class="comment">        float* y_b = y.data() + b * D;</span></div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span><span class="comment">        for (int i = 0; i &lt; D; ++i) {</span></div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span><span class="comment">          for (int j = 0; j &lt; D; ++j) {</span></div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span><span class="comment">            float indicator = i == j ? 1.0f : 0.0f;</span></div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span><span class="comment">            //            x_grad(b, i) += y_grad(b, j) * y(b, i) * (indicator -</span></div>
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno">  711</span><span class="comment">            //            y(b, j));</span></div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span><span class="comment">            x_grad_b[i] += y_grad_b[j] * y_b[i] * (indicator - y_b[j]);</span></div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span><span class="comment">          }</span></div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span><span class="comment">        }</span></div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span><span class="comment">      }</span></div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span><span class="comment">    };</span></div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span><span class="comment"></span> </div>
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno">  718</span><span class="comment">    int thread_num = g_cpu_device.numThreads();</span></div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span><span class="comment">    Eigen::Barrier barrier(thread_num);</span></div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span><span class="comment">    for (int t = 0; t &lt; thread_num; ++t) {</span></div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span><span class="comment">      auto range = SplitRange(B, t, thread_num);</span></div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span><span class="comment">      g_cpu_device.enqueue_with_barrier(&amp;barrier, fn, range.first,</span></div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span><span class="comment">                                        range.second);</span></div>
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno">  724</span><span class="comment">    }</span></div>
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno">  725</span><span class="comment">    barrier.Wait();</span></div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span><span class="comment">    */</span></div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span>  }</div>
</div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span>};</div>
</div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span> </div>
<div class="foldopen" id="foldopen00730" data-start="{" data-end="};">
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html">  730</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1SoftmaxCrossEntropy.html">SoftmaxCrossEntropy</a> {</div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1SoftmaxCrossEntropy.html#a353b6bc3af73be364a53c3ae80019bd3">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">  732</a></span>  <span class="keyword">enum</span> <a class="code hl_enumeration" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">Reduction</a> { <a class="code hl_enumvalue" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04add36ad20b6e6cbc891022762da1b385d">MEAN</a>, <a class="code hl_enumvalue" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04a44fe5ec5ac95c2fce33759616a32a6ad">SUM</a> };</div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span> </div>
<div class="foldopen" id="foldopen00734" data-start="{" data-end="}">
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a61c0fc7c4f30c38c37b2a69353aebfb8">  734</a></span>  <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#a61c0fc7c4f30c38c37b2a69353aebfb8">SoftmaxCrossEntropy</a>(<a class="code hl_enumeration" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">Reduction</a> reduction = Reduction::MEAN)</div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span>      : <a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a>(reduction) {}</div>
</div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span> </div>
<div class="foldopen" id="foldopen00737" data-start="{" data-end="}">
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#afb6a8fe2404484125128f5b2cafe7806">  737</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#afb6a8fe2404484125128f5b2cafe7806">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> logits,</div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span>               <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> targets, <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> probs,</div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span>               <span class="keywordtype">float</span>* loss) {</div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span>    <span class="comment">// logits: [B, C], targets: [B,], probs:[B, C], loss: scalar</span></div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span>    <span class="keywordtype">int</span> B = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>() &amp;&amp; B == probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>, probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span> </div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span>    <span class="comment">// apply softmax to convert logits to (normalized) probabilities</span></div>
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno">  746</span>    <a class="code hl_function" href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">Softmax::Forward</a>(logits, probs);</div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span> </div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span>    <span class="comment">// targets: [B,]</span></div>
<div class="line"><a id="l00749" name="l00749"></a><span class="lineno">  749</span>    *loss = 0.0f;</div>
<div class="line"><a id="l00750" name="l00750"></a><span class="lineno">  750</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> &lt; targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(); ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>) {</div>
<div class="line"><a id="l00751" name="l00751"></a><span class="lineno">  751</span>      <span class="keywordtype">int</span> ix = targets[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>];</div>
<div class="line"><a id="l00752" name="l00752"></a><span class="lineno">  752</span>      *loss += -std::log(probs(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>, ix));</div>
<div class="line"><a id="l00753" name="l00753"></a><span class="lineno">  753</span>    }</div>
<div class="line"><a id="l00754" name="l00754"></a><span class="lineno">  754</span> </div>
<div class="line"><a id="l00755" name="l00755"></a><span class="lineno">  755</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a> == Reduction::MEAN) {</div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span>      *loss /= <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(B);</div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span>    }</div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span>  }</div>
</div>
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno">  759</span> </div>
<div class="foldopen" id="foldopen00760" data-start="{" data-end="}">
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#abd096903b589b4f9575bfca0e5b7b49d">  760</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#abd096903b589b4f9575bfca0e5b7b49d">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> probs,</div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span>                <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> targets,</div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span>                <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> logits_grad) {</div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span>    <span class="comment">// probs: [B, C], targets: [B,]</span></div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span>    <span class="comment">// logits_grad: [B, C]</span></div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span>    <span class="keywordtype">int</span> B = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>() &amp;&amp; B == logits_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>, logits_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span> </div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span>    <span class="keywordtype">float</span> factor =</div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span>        <a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a> == Reduction::MEAN ? 1.0f / <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(B) : 1.0f;</div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span> </div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a> &lt; B; ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>) {</div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span>      <span class="keywordtype">int</span> ix = targets[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>];</div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>; ++c) {</div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span>        <span class="keywordtype">float</span> indicator = c == ix ? 1.0f : 0.0f;</div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span>        logits_grad(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>, c) += (probs(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>, c) - indicator) * factor;</div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span>      }</div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span>    }</div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span>  }</div>
</div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span> </div>
<div class="foldopen" id="foldopen00781" data-start="{" data-end="}">
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a7688dce4252afd47dbb64a0b5717ea2c">  781</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#a7688dce4252afd47dbb64a0b5717ea2c">ForwardAndBackward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> logits,</div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> labels,</div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> scratch,</div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> loss,</div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> logit_grad) {</div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span>    <span class="comment">// logits: [B, C], targets: [B,], probs:[B, C], loss: scalar</span></div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno">  787</span>    <span class="keywordtype">int</span> B = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == labels.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> == labels.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == logit_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> == logit_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(B, scratch.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(B, loss.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00792" name="l00792"></a><span class="lineno">  792</span> </div>
<div class="line"><a id="l00793" name="l00793"></a><span class="lineno">  793</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size = B, num_class = <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>;</div>
<div class="line"><a id="l00794" name="l00794"></a><span class="lineno">  794</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 1&gt;</a> along_class = {1};</div>
<div class="line"><a id="l00795" name="l00795"></a><span class="lineno">  795</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> batch_by_one = {batch_size, 1};</div>
<div class="line"><a id="l00796" name="l00796"></a><span class="lineno">  796</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> one_by_class = {1, num_class};</div>
<div class="line"><a id="l00797" name="l00797"></a><span class="lineno">  797</span> </div>
<div class="line"><a id="l00798" name="l00798"></a><span class="lineno">  798</span>    <span class="comment">// max_logits along classes.</span></div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span>    scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) = logits.maximum(along_class);</div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span> </div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span>    <span class="comment">// logits - max_logits.</span></div>
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno">  802</span>    logit_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) =</div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span>        logits - scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#adc5c658be289d8944ca3c8e7a2fac1f7">reshape</a>(batch_by_one).broadcast(one_by_class);</div>
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno">  804</span> </div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span>    <span class="comment">// sum(exp(logits - max_logits)) along classes.</span></div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span>    scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) = logit_grad.exp().sum(along_class);</div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span> </div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span>    <span class="comment">// NOTE: Eigen on GPU dispatches to an optimized implementation</span></div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span>    <span class="comment">// for an expression of the form lhs = rhs.sum().</span></div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span>    <span class="comment">// lhs = -rhs.sum() doesn&#39;t match the above pattern, so folding in the</span></div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span>    <span class="comment">// negation before calling sum().</span></div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span>    <span class="comment">//  sum(-labels *</span></div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span>    <span class="comment">//     ((logits - max_logits) - log(sum(exp(logits - max_logits)))))</span></div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span>    <span class="comment">//  along classes</span></div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span>    loss.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) =</div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span>        (labels * (scratch.log().reshape(batch_by_one).broadcast(one_by_class) -</div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span>                   logit_grad))</div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span>            .sum(along_class);</div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span> </div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span>    <span class="comment">// backprop: prob - labels, where</span></div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span>    <span class="comment">//   prob = exp(logits - max_logits) / sum(exp(logits - max_logits))</span></div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span>    logit_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) =</div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span>        (logit_grad.exp() /</div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span>         scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#adc5c658be289d8944ca3c8e7a2fac1f7">reshape</a>(batch_by_one).broadcast(one_by_class)) -</div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span>        labels;</div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span>  }</div>
</div>
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno">  827</span> </div>
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno">  828</span>  <a class="code hl_enumeration" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">Reduction</a> <a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a>;</div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span>};</div>
</div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span> </div>
<div class="foldopen" id="foldopen00831" data-start="{" data-end="};">
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno"><a class="line" href="structnn_1_1CrossEntropy.html">  831</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structnn_1_1CrossEntropy.html">CrossEntropy</a> {</div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1CrossEntropy.html#ac2c82ea85793511ae3c7a6e58961ba52">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno"><a class="line" href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3">  833</a></span>  <span class="keyword">enum</span> <a class="code hl_enumeration" href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3">Reduction</a> { <a class="code hl_enumvalue" href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3a61bc49dd30d67bb2e67230b59719e56d">MEAN</a>, <a class="code hl_enumvalue" href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3ae3282ef2d73939de84601a2aabc567ad">SUM</a> };</div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span> </div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno"><a class="line" href="structnn_1_1CrossEntropy.html#a317c3ff9babc59fb78b4301edf3893e4">  835</a></span>  <a class="code hl_function" href="structnn_1_1CrossEntropy.html#a317c3ff9babc59fb78b4301edf3893e4">CrossEntropy</a>(<a class="code hl_enumeration" href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3">Reduction</a> reduction = Reduction::MEAN) : <a class="code hl_variable" href="structnn_1_1CrossEntropy.html#a8df82dc1e730e73cb3636d0d584158dc">reduction_</a>(reduction) {}</div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span> </div>
<div class="foldopen" id="foldopen00837" data-start="{" data-end="}">
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno"><a class="line" href="structnn_1_1CrossEntropy.html#a0a71ab9cf2092f7cfebe57f783285bb0">  837</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1CrossEntropy.html#a0a71ab9cf2092f7cfebe57f783285bb0">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> probs,</div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span>               <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> targets, <span class="keywordtype">float</span>* loss) {</div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span>    <span class="comment">// probs:[B, C], targets: [B,] loss: scalar</span></div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span>    <span class="keywordtype">int</span> B = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(B, targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>());</div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span> </div>
<div class="line"><a id="l00843" name="l00843"></a><span class="lineno">  843</span>    <span class="comment">// targets: [B,]</span></div>
<div class="line"><a id="l00844" name="l00844"></a><span class="lineno">  844</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> &lt; targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(); ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>) {</div>
<div class="line"><a id="l00845" name="l00845"></a><span class="lineno">  845</span>      <span class="keywordtype">int</span> ix = targets[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>];</div>
<div class="line"><a id="l00846" name="l00846"></a><span class="lineno">  846</span>      *loss += -std::log(probs(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>, ix));</div>
<div class="line"><a id="l00847" name="l00847"></a><span class="lineno">  847</span>    }</div>
<div class="line"><a id="l00848" name="l00848"></a><span class="lineno">  848</span> </div>
<div class="line"><a id="l00849" name="l00849"></a><span class="lineno">  849</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="structnn_1_1CrossEntropy.html#a8df82dc1e730e73cb3636d0d584158dc">reduction_</a> == Reduction::MEAN) {</div>
<div class="line"><a id="l00850" name="l00850"></a><span class="lineno">  850</span>      *loss /= <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(B);</div>
<div class="line"><a id="l00851" name="l00851"></a><span class="lineno">  851</span>    }</div>
<div class="line"><a id="l00852" name="l00852"></a><span class="lineno">  852</span>  }</div>
</div>
<div class="line"><a id="l00853" name="l00853"></a><span class="lineno">  853</span> </div>
<div class="foldopen" id="foldopen00854" data-start="{" data-end="}">
<div class="line"><a id="l00854" name="l00854"></a><span class="lineno"><a class="line" href="structnn_1_1CrossEntropy.html#a1fd65ea7f1a8f32574363455434ce234">  854</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1CrossEntropy.html#a1fd65ea7f1a8f32574363455434ce234">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> probs,</div>
<div class="line"><a id="l00855" name="l00855"></a><span class="lineno">  855</span>                <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> targets,</div>
<div class="line"><a id="l00856" name="l00856"></a><span class="lineno">  856</span>                <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> probs_grad) {</div>
<div class="line"><a id="l00857" name="l00857"></a><span class="lineno">  857</span>    <span class="comment">// probs: [B, C], targets: [B,]</span></div>
<div class="line"><a id="l00858" name="l00858"></a><span class="lineno">  858</span>    <span class="comment">// probs_grad: [B, C]</span></div>
<div class="line"><a id="l00859" name="l00859"></a><span class="lineno">  859</span>    <span class="keywordtype">int</span> B = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00860" name="l00860"></a><span class="lineno">  860</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>() &amp;&amp; B == probs_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00861" name="l00861"></a><span class="lineno">  861</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>, probs_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00862" name="l00862"></a><span class="lineno">  862</span> </div>
<div class="line"><a id="l00863" name="l00863"></a><span class="lineno">  863</span>    <span class="keywordtype">float</span> factor =</div>
<div class="line"><a id="l00864" name="l00864"></a><span class="lineno">  864</span>        <a class="code hl_variable" href="structnn_1_1CrossEntropy.html#a8df82dc1e730e73cb3636d0d584158dc">reduction_</a> == Reduction::MEAN ? 1.0f / <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(B) : 1.0f;</div>
<div class="line"><a id="l00865" name="l00865"></a><span class="lineno">  865</span> </div>
<div class="line"><a id="l00866" name="l00866"></a><span class="lineno">  866</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a> &lt; B; ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>) {</div>
<div class="line"><a id="l00867" name="l00867"></a><span class="lineno">  867</span>      <span class="keywordtype">int</span> ix = targets[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>];</div>
<div class="line"><a id="l00868" name="l00868"></a><span class="lineno">  868</span>      probs_grad(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>, ix) += -1.0f / probs(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>, ix) * factor;</div>
<div class="line"><a id="l00869" name="l00869"></a><span class="lineno">  869</span>    }</div>
<div class="line"><a id="l00870" name="l00870"></a><span class="lineno">  870</span>  }</div>
</div>
<div class="line"><a id="l00871" name="l00871"></a><span class="lineno">  871</span> </div>
<div class="line"><a id="l00872" name="l00872"></a><span class="lineno">  872</span>  <a class="code hl_enumeration" href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3">Reduction</a> <a class="code hl_variable" href="structnn_1_1CrossEntropy.html#a8df82dc1e730e73cb3636d0d584158dc">reduction_</a>;</div>
<div class="line"><a id="l00873" name="l00873"></a><span class="lineno">  873</span>};</div>
</div>
<div class="line"><a id="l00874" name="l00874"></a><span class="lineno">  874</span> </div>
<div class="line"><a id="l00875" name="l00875"></a><span class="lineno">  875</span>}  <span class="comment">// namespace nn</span></div>
<div class="line"><a id="l00876" name="l00876"></a><span class="lineno">  876</span> </div>
<div class="line"><a id="l00877" name="l00877"></a><span class="lineno">  877</span><span class="preprocessor">#endif  </span><span class="comment">// LLM_CPP__NN_HPP_</span></div>
<div class="ttc" id="aOriginalStuff_2abseil-cpp_2absl_2algorithm_2container_8h_html"><div class="ttname"><a href="OriginalStuff_2abseil-cpp_2absl_2algorithm_2container_8h.html">container.h</a></div></div>
<div class="ttc" id="aOriginalStuff_2abseil-cpp_2absl_2log_2check_8h_html"><div class="ttname"><a href="OriginalStuff_2abseil-cpp_2absl_2log_2check_8h.html">check.h</a></div></div>
<div class="ttc" id="aOriginalStuff_2abseil-cpp_2absl_2log_2log_8h_html"><div class="ttname"><a href="OriginalStuff_2abseil-cpp_2absl_2log_2log_8h.html">log.h</a></div></div>
<div class="ttc" id="aOriginalStuff_2abseil-cpp_2absl_2strings_2string__view_8h_html"><div class="ttname"><a href="OriginalStuff_2abseil-cpp_2absl_2strings_2string__view_8h.html">string_view.h</a></div></div>
<div class="ttc" id="aOriginalStuff_2abseil-cpp_2absl_2types_2span_8h_html"><div class="ttname"><a href="OriginalStuff_2abseil-cpp_2absl_2types_2span_8h.html">span.h</a></div></div>
<div class="ttc" id="aOriginalStuff_2llmc_2rand_8h_html"><div class="ttname"><a href="OriginalStuff_2llmc_2rand_8h.html">rand.h</a></div></div>
<div class="ttc" id="aOriginalStuff_2tensor__util_8hpp_html"><div class="ttname"><a href="OriginalStuff_2tensor__util_8hpp.html">tensor_util.hpp</a></div></div>
<div class="ttc" id="aOriginalStuff_2tensor__util_8hpp_html_a30c79fba785f603a86fa02252305fbed"><div class="ttname"><a href="OriginalStuff_2tensor__util_8hpp.html#a30c79fba785f603a86fa02252305fbed">MakeMatrix</a></div><div class="ttdeci">TTypes&lt; T &gt;::Matrix MakeMatrix(T *t, int rows, int cols)</div><div class="ttdef"><b>Definition</b> tensor_util.hpp:25</div></div>
<div class="ttc" id="aOriginalStuff_2tensor__util_8hpp_html_a9a087a9b5b6b2f4a06af705501667b9b"><div class="ttname"><a href="OriginalStuff_2tensor__util_8hpp.html#a9a087a9b5b6b2f4a06af705501667b9b">MakeFlat</a></div><div class="ttdeci">TTypes&lt; T &gt;::Flat MakeFlat(T *t, int length)</div><div class="ttdef"><b>Definition</b> tensor_util.hpp:11</div></div>
<div class="ttc" id="aParameter_8hpp_html_ab7cf30991ed49f035a787185466250cc"><div class="ttname"><a href="Parameter_8hpp.html#ab7cf30991ed49f035a787185466250cc">MATCH_TYPE_AND_ENUM</a></div><div class="ttdeci">#define MATCH_TYPE_AND_ENUM(TYPE, ENUM)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:146</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2container_2btree__benchmark_8cc_html_a717c50cfde3924051c279a89096afd3d"><div class="ttname"><a href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a></div><div class="ttdeci">uint64_t i</div><div class="ttdef"><b>Definition</b> btree_benchmark.cc:232</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2container_2btree__test_8cc_html_a76f11d9a0a47b94f72c2d0e77fb32240"><div class="ttname"><a href="abseil-cpp_2absl_2container_2btree__test_8cc.html#a76f11d9a0a47b94f72c2d0e77fb32240">n</a></div><div class="ttdeci">int n</div><div class="ttdef"><b>Definition</b> btree_test.cc:958</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2container_2internal_2layout__test_8cc_html_a633ab603a49d0a046734a0f3e6de45e9"><div class="ttname"><a href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a633ab603a49d0a046734a0f3e6de45e9">to</a></div><div class="ttdeci">size_t to</div><div class="ttdef"><b>Definition</b> layout_test.cc:1658</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2container_2internal_2layout__test_8cc_html_a66a6152caa0d2dec6985ed86838ba876"><div class="ttname"><a href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#a66a6152caa0d2dec6985ed86838ba876">from</a></div><div class="ttdeci">size_t from</div><div class="ttdef"><b>Definition</b> layout_test.cc:1657</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2container_2internal_2layout__test_8cc_html_ad66453096871179e6c6effe0df4b483b"><div class="ttname"><a href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a></div><div class="ttdeci">uint64_t b</div><div class="ttdef"><b>Definition</b> layout_test.cc:58</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2hash_2internal_2city__test_8cc_html_ac54ae397901fe700628cafadea3c5208"><div class="ttname"><a href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a></div><div class="ttdeci">#define C(x)</div><div class="ttdef"><b>Definition</b> city_test.cc:49</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2log_2check_8h_html_a3e1cfef60e774a81f30eaddf26a3a274"><div class="ttname"><a href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a></div><div class="ttdeci">#define CHECK(condition)</div><div class="ttdef"><b>Definition</b> check.h:57</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2log_2check_8h_html_a4bd2e815ca2f702a4b6aa744b1ff3b82"><div class="ttname"><a href="abseil-cpp_2absl_2log_2check_8h.html#a4bd2e815ca2f702a4b6aa744b1ff3b82">CHECK_LT</a></div><div class="ttdeci">#define CHECK_LT(val1, val2)</div><div class="ttdef"><b>Definition</b> check.h:122</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2log_2check_8h_html_a7c0ce053b28d53aa4eaf3eb7fb71663b"><div class="ttname"><a href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a></div><div class="ttdeci">#define CHECK_EQ(val1, val2)</div><div class="ttdef"><b>Definition</b> check.h:116</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2log_2check_8h_html_a7e03ec13560fa94a8fea569960d7efc6"><div class="ttname"><a href="abseil-cpp_2absl_2log_2check_8h.html#a7e03ec13560fa94a8fea569960d7efc6">CHECK_GT</a></div><div class="ttdeci">#define CHECK_GT(val1, val2)</div><div class="ttdef"><b>Definition</b> check.h:126</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2strings_2cord__analysis_8cc_html_a3fab45bb4d7cd7e889bdf00080096e8e"><div class="ttname"><a href="abseil-cpp_2absl_2strings_2cord__analysis_8cc.html#a3fab45bb4d7cd7e889bdf00080096e8e">total</a></div><div class="ttdeci">size_t total</div><div class="ttdef"><b>Definition</b> cord_analysis.cc:56</div></div>
<div class="ttc" id="aclassEigen_1_1Matrix_html"><div class="ttname"><a href="classEigen_1_1Matrix.html">Eigen::Matrix</a></div><div class="ttdoc">The matrix class, also used for vectors and row-vectors.</div><div class="ttdef"><b>Definition</b> ForwardDeclarations.h:70</div></div>
<div class="ttc" id="aclassEigen_1_1TensorBase_html_ac18f87a86c01efc64d8f7235596d5d7d"><div class="ttname"><a href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">Eigen::TensorBase::device</a></div><div class="ttdeci">TensorDevice&lt; Derived, DeviceType &gt; device(const DeviceType &amp;dev)</div><div class="ttdef"><b>Definition</b> TensorBase.h:1145</div></div>
<div class="ttc" id="aclassEigen_1_1TensorBase_html_adc5c658be289d8944ca3c8e7a2fac1f7"><div class="ttname"><a href="classEigen_1_1TensorBase.html#adc5c658be289d8944ca3c8e7a2fac1f7">Eigen::TensorBase::reshape</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const TensorReshapingOp&lt; const NewDimensions, const Derived &gt; reshape(const NewDimensions &amp;newDimensions) const</div><div class="ttdef"><b>Definition</b> TensorBase.h:1055</div></div>
<div class="ttc" id="aclassEigen_1_1TensorMap_html"><div class="ttname"><a href="classEigen_1_1TensorMap.html">Eigen::TensorMap</a></div><div class="ttdoc">A tensor expression mapping an existing array of data.</div><div class="ttdef"><b>Definition</b> TensorMap.h:30</div></div>
<div class="ttc" id="aclassEigen_1_1TensorMap_html_a715f830bbfa94beb8b2deb053530afd6"><div class="ttname"><a href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">Eigen::TensorMap::size</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index size() const</div><div class="ttdef"><b>Definition</b> TensorMap.h:135</div></div>
<div class="ttc" id="aclassEigen_1_1TensorMap_html_a735ad83edfacfcb9173e59ed861e6bbf"><div class="ttname"><a href="classEigen_1_1TensorMap.html#a735ad83edfacfcb9173e59ed861e6bbf">Eigen::TensorMap::data</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE StoragePointerType data()</div><div class="ttdef"><b>Definition</b> TensorMap.h:137</div></div>
<div class="ttc" id="aclassEigen_1_1TensorMap_html_adfb930b8289836aad40d64171bde46a1"><div class="ttname"><a href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">Eigen::TensorMap::dimension</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index dimension(Index n) const</div><div class="ttdef"><b>Definition</b> TensorMap.h:131</div></div>
<div class="ttc" id="aclassEigen_1_1ThreadPoolTempl_html"><div class="ttname"><a href="classEigen_1_1ThreadPoolTempl.html">Eigen::ThreadPoolTempl</a></div><div class="ttdef"><b>Definition</b> NonBlockingThreadPool.h:16</div></div>
<div class="ttc" id="aclassEigen_1_1array_html"><div class="ttname"><a href="classEigen_1_1array.html">Eigen::array</a></div><div class="ttdef"><b>Definition</b> EmulateArray.h:21</div></div>
<div class="ttc" id="aclassEigen_1_1internal_1_1TensorLazyEvaluatorReadOnly_html_a9be5f49eeb9fb048cc4f036588a41fc5"><div class="ttname"><a href="classEigen_1_1internal_1_1TensorLazyEvaluatorReadOnly.html#a9be5f49eeb9fb048cc4f036588a41fc5">Eigen::internal::TensorLazyEvaluatorReadOnly::data</a></div><div class="ttdeci">virtual EIGEN_DEVICE_FUNC const Scalar * data() const</div><div class="ttdef"><b>Definition</b> TensorRef.h:62</div></div>
<div class="ttc" id="aclassabsl_1_1Span_html"><div class="ttname"><a href="classabsl_1_1Span.html">absl::Span</a></div><div class="ttdef"><b>Definition</b> span.h:182</div></div>
<div class="ttc" id="aclassabsl_1_1Span_html_a92186c247036e10dd12603c09f8b8797"><div class="ttname"><a href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">absl::Span::size</a></div><div class="ttdeci">constexpr size_type size() const noexcept</div><div class="ttdef"><b>Definition</b> span.h:315</div></div>
<div class="ttc" id="aclassabsl_1_1Span_html_ab73e4be6262f844714eb7c48225b605b"><div class="ttname"><a href="classabsl_1_1Span.html#ab73e4be6262f844714eb7c48225b605b">absl::Span::data</a></div><div class="ttdeci">constexpr pointer data() const noexcept</div><div class="ttdef"><b>Definition</b> span.h:310</div></div>
<div class="ttc" id="adev_2cuda_2common_8h_html_a73bc90d2e378d172e206b528b3756c5a"><div class="ttname"><a href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a></div><div class="ttdeci">float floatX</div><div class="ttdef"><b>Definition</b> common.h:199</div></div>
<div class="ttc" id="aeigen_2Eigen_2src_2plugins_2ArrayCwiseUnaryOps_8h_html_ad816d4a0c05f21e660e91e9febb1b900"><div class="ttname"><a href="eigen_2Eigen_2src_2plugins_2ArrayCwiseUnaryOps_8h.html#ad816d4a0c05f21e660e91e9febb1b900">cube</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC const CubeReturnType cube() const</div><div class="ttdef"><b>Definition</b> ArrayCwiseUnaryOps.h:439</div></div>
<div class="ttc" id="aeigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h_html_ab2b6b0c222cd1ce70d6a831f57241e59"><div class="ttname"><a href="eigen_2unsupported_2Eigen_2CXX11_2src_2Tensor_2TensorIntDiv_8h.html#ab2b6b0c222cd1ce70d6a831f57241e59">N</a></div><div class="ttdeci">static const int N</div><div class="ttdef"><b>Definition</b> TensorIntDiv.h:88</div></div>
<div class="ttc" id="agroup__enums_html_gga39e3366ff5554d731e7dc8bb642f83cdae38aad7d66fecfb213fce453edff4c7a"><div class="ttname"><a href="group__enums.html#gga39e3366ff5554d731e7dc8bb642f83cdae38aad7d66fecfb213fce453edff4c7a">Eigen::StrictlyUpper</a></div><div class="ttdeci">@ StrictlyUpper</div><div class="ttdef"><b>Definition</b> Constants.h:223</div></div>
<div class="ttc" id="allmc_2rand_8h_html_a486e23d6acb57456d73173c03f66a052"><div class="ttname"><a href="llmc_2rand_8h.html#a486e23d6acb57456d73173c03f66a052">normal_</a></div><div class="ttdeci">void normal_(float *data, unsigned int numel, float mean, float std, mt19937_state *state)</div><div class="ttdef"><b>Definition</b> rand.h:197</div></div>
<div class="ttc" id="allmc_2rand_8h_html_aaf0aeafba5647f2ad3bb2cae66e5ed44"><div class="ttname"><a href="llmc_2rand_8h.html#aaf0aeafba5647f2ad3bb2cae66e5ed44">uniform_</a></div><div class="ttdeci">void uniform_(float *data, unsigned int numel, float from, float to, mt19937_state *state)</div><div class="ttdef"><b>Definition</b> rand.h:160</div></div>
<div class="ttc" id="allmc_2rand_8h_html_ab64d400dcc18bac40a0c38b316caa406"><div class="ttname"><a href="llmc_2rand_8h.html#ab64d400dcc18bac40a0c38b316caa406">manual_seed</a></div><div class="ttdeci">void manual_seed(mt19937_state *state, unsigned int seed)</div><div class="ttdef"><b>Definition</b> rand.h:106</div></div>
<div class="ttc" id="anamespaceEigen_1_1numext_html_a26035668345422b5f30be2124b0b6f6e"><div class="ttname"><a href="namespaceEigen_1_1numext.html#a26035668345422b5f30be2124b0b6f6e">Eigen::numext::int64_t</a></div><div class="ttdeci">::int64_t int64_t</div><div class="ttdef"><b>Definition</b> Meta.h:59</div></div>
<div class="ttc" id="anamespaceEigen_1_1numext_html_a5cda5c90c4e51bbe6611e423fd9c176f"><div class="ttname"><a href="namespaceEigen_1_1numext.html#a5cda5c90c4e51bbe6611e423fd9c176f">Eigen::numext::q</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC const Scalar &amp; q</div><div class="ttdef"><b>Definition</b> SpecialFunctionsImpl.h:1984</div></div>
<div class="ttc" id="anamespaceabsl_html_a1b228348b0d7cd46a5d9a1d4daf702cb"><div class="ttname"><a href="namespaceabsl.html#a1b228348b0d7cd46a5d9a1d4daf702cb">absl::c_fill</a></div><div class="ttdeci">void c_fill(C &amp;c, const T &amp;value)</div><div class="ttdef"><b>Definition</b> container.h:690</div></div>
<div class="ttc" id="anamespacenn_html"><div class="ttname"><a href="namespacenn.html">nn</a></div><div class="ttdef"><b>Definition</b> Embedding.hpp:11</div></div>
<div class="ttc" id="anamespacenn_html_a15e2232b24a304936a0f3d6452ab7095"><div class="ttname"><a href="namespacenn.html#a15e2232b24a304936a0f3d6452ab7095">nn::Activation</a></div><div class="ttdeci">Parameter Activation</div><div class="ttdef"><b>Definition</b> Parameter.hpp:380</div></div>
<div class="ttc" id="anamespacenn_html_a2b75086de2e32662267822633e0399d7"><div class="ttname"><a href="namespacenn.html#a2b75086de2e32662267822633e0399d7">nn::SplitRange</a></div><div class="ttdeci">std::pair&lt; int, int &gt; SplitRange(int total, int idx, int n)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:117</div></div>
<div class="ttc" id="anamespacenn_html_a5268109b8c87089a840f743713f8781f"><div class="ttname"><a href="namespacenn.html#a5268109b8c87089a840f743713f8781f">nn::KaimingUniformFill</a></div><div class="ttdeci">void KaimingUniformFill(absl::Span&lt; float &gt; weight, int in_features)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:79</div></div>
<div class="ttc" id="anamespacenn_html_a7a0bfd75fc17c62ba9e681cd3d346efc"><div class="ttname"><a href="namespacenn.html#a7a0bfd75fc17c62ba9e681cd3d346efc">nn::NormalFill</a></div><div class="ttdeci">void NormalFill(absl::Span&lt; float &gt; weight, float mean=0.0, float std=1.0)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:67</div></div>
<div class="ttc" id="anamespacenn_html_aa7f7fc1fcad89e0745dbae4bfad4d356"><div class="ttname"><a href="namespacenn.html#aa7f7fc1fcad89e0745dbae4bfad4d356">nn::UniformFill</a></div><div class="ttdeci">void UniformFill(absl::Span&lt; float &gt; weight, float from=0.0, float to=1.0)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:55</div></div>
<div class="ttc" id="anamespacenn_html_ac7b27125b312174adc4f7f9a3f478e76"><div class="ttname"><a href="namespacenn.html#ac7b27125b312174adc4f7f9a3f478e76">nn::g_mt19937_state</a></div><div class="ttdeci">mt19937_state g_mt19937_state</div><div class="ttdef"><b>Definition</b> Parameter.hpp:38</div></div>
<div class="ttc" id="anamespacenn_html_acb3bf801e394f195e8cece47de7b5311"><div class="ttname"><a href="namespacenn.html#acb3bf801e394f195e8cece47de7b5311">nn::UpperTriangularWithNegativeInf</a></div><div class="ttdeci">void UpperTriangularWithNegativeInf(typename TTypes&lt; float &gt;::Matrix matrix)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:91</div></div>
<div class="ttc" id="anamespacenn_html_ace7109b820ab3e99ec8c4fbfe7c0f13e"><div class="ttname"><a href="namespacenn.html#ace7109b820ab3e99ec8c4fbfe7c0f13e">nn::OntHot</a></div><div class="ttdeci">void OntHot(typename TTypes&lt; int &gt;::ConstFlat target, typename TTypes&lt; float &gt;::Matrix label)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:106</div></div>
<div class="ttc" id="anamespacenn_html_aceb3ca07330f23a6bffe93e606fcc6d8"><div class="ttname"><a href="namespacenn.html#aceb3ca07330f23a6bffe93e606fcc6d8">nn::g_thread_pool</a></div><div class="ttdeci">Eigen::ThreadPool g_thread_pool(16)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:34</div></div>
<div class="ttc" id="anamespacenn_html_af51d93c61a072d59ba2e321b7fac681c"><div class="ttname"><a href="namespacenn.html#af51d93c61a072d59ba2e321b7fac681c">nn::ManualSeed</a></div><div class="ttdeci">void ManualSeed(unsigned int seed)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:40</div></div>
<div class="ttc" id="anamespacenn_html_afadc7a301a4a916a264a59541a7cbfcf"><div class="ttname"><a href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcf">nn::DataType</a></div><div class="ttdeci">DataType</div><div class="ttdef"><b>Definition</b> Parameter.hpp:127</div></div>
<div class="ttc" id="anamespacenn_html_afadc7a301a4a916a264a59541a7cbfcfa619d8e532169cd16e25ef103f28e3213"><div class="ttname"><a href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa619d8e532169cd16e25ef103f28e3213">nn::DT_FLOAT</a></div><div class="ttdeci">@ DT_FLOAT</div><div class="ttdef"><b>Definition</b> Parameter.hpp:127</div></div>
<div class="ttc" id="anamespacenn_html_afadc7a301a4a916a264a59541a7cbfcfa6a6aeedaa380640cdd4933339270f7cd"><div class="ttname"><a href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfa6a6aeedaa380640cdd4933339270f7cd">nn::DT_INT32</a></div><div class="ttdeci">@ DT_INT32</div><div class="ttdef"><b>Definition</b> Parameter.hpp:127</div></div>
<div class="ttc" id="anamespacenn_html_afadc7a301a4a916a264a59541a7cbfcfae00f2994306b9bd91c2165b87d5502f3"><div class="ttname"><a href="namespacenn.html#afadc7a301a4a916a264a59541a7cbfcfae00f2994306b9bd91c2165b87d5502f3">nn::DT_HALF</a></div><div class="ttdeci">@ DT_HALF</div><div class="ttdef"><b>Definition</b> Parameter.hpp:127</div></div>
<div class="ttc" id="anamespacenn_html_afd34dfbb2119f475e4582064af7a06f0"><div class="ttname"><a href="namespacenn.html#afd34dfbb2119f475e4582064af7a06f0">nn::ConstantFill</a></div><div class="ttdeci">void ConstantFill(absl::Span&lt; T &gt; weight, T C)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:45</div></div>
<div class="ttc" id="anamespacestd_html"><div class="ttname"><a href="namespacestd.html">std</a></div><div class="ttdef"><b>Definition</b> hash_function_defaults_test.cc:656</div></div>
<div class="ttc" id="astructEigen_1_1IndexPair_html"><div class="ttname"><a href="structEigen_1_1IndexPair.html">Eigen::IndexPair</a></div><div class="ttdef"><b>Definition</b> TensorMeta.h:247</div></div>
<div class="ttc" id="astructEigen_1_1half_html"><div class="ttname"><a href="structEigen_1_1half.html">Eigen::half</a></div><div class="ttdef"><b>Definition</b> Half.h:142</div></div>
<div class="ttc" id="astructTTypes_html_aa53f19202b54ddd0fe543e2e7f771caf"><div class="ttname"><a href="structTTypes.html#aa53f19202b54ddd0fe543e2e7f771caf">TTypes::UnalignedConstFlat</a></div><div class="ttdeci">Eigen::TensorMap&lt; Eigen::Tensor&lt; const T, 1, Eigen::RowMajor, IndexType &gt; &gt; UnalignedConstFlat</div><div class="ttdef"><b>Definition</b> tensor_types.hpp:66</div></div>
<div class="ttc" id="astructTTypes_html_aea634ba279401433e58c5e59b008cf36"><div class="ttname"><a href="structTTypes.html#aea634ba279401433e58c5e59b008cf36">TTypes::UnalignedFlat</a></div><div class="ttdeci">Eigen::TensorMap&lt; Eigen::Tensor&lt; T, 1, Eigen::RowMajor, IndexType &gt; &gt; UnalignedFlat</div><div class="ttdef"><b>Definition</b> tensor_types.hpp:63</div></div>
<div class="ttc" id="astructmt19937__state_html"><div class="ttname"><a href="structmt19937__state.html">mt19937_state</a></div><div class="ttdef"><b>Definition</b> rand.h:98</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html"><div class="ttname"><a href="structnn_1_1CrossEntropy.html">nn::CrossEntropy</a></div><div class="ttdef"><b>Definition</b> nn.hpp:831</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_a0a71ab9cf2092f7cfebe57f783285bb0"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#a0a71ab9cf2092f7cfebe57f783285bb0">nn::CrossEntropy::Forward</a></div><div class="ttdeci">void Forward(typename TTypes&lt; T &gt;::ConstMatrix probs, absl::Span&lt; const int &gt; targets, float *loss)</div><div class="ttdef"><b>Definition</b> nn.hpp:837</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_a1fd65ea7f1a8f32574363455434ce234"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#a1fd65ea7f1a8f32574363455434ce234">nn::CrossEntropy::Backward</a></div><div class="ttdeci">void Backward(typename TTypes&lt; T &gt;::ConstMatrix probs, absl::Span&lt; const int &gt; targets, typename TTypes&lt; T &gt;::Matrix probs_grad)</div><div class="ttdef"><b>Definition</b> nn.hpp:854</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_a317c3ff9babc59fb78b4301edf3893e4"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#a317c3ff9babc59fb78b4301edf3893e4">nn::CrossEntropy::CrossEntropy</a></div><div class="ttdeci">CrossEntropy(Reduction reduction=Reduction::MEAN)</div><div class="ttdef"><b>Definition</b> nn.hpp:835</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_a66479cf14574903516fdc5fd59b4b8b3"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3">nn::CrossEntropy::Reduction</a></div><div class="ttdeci">Reduction</div><div class="ttdef"><b>Definition</b> Loss.hpp:14</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_a66479cf14574903516fdc5fd59b4b8b3a61bc49dd30d67bb2e67230b59719e56d"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3a61bc49dd30d67bb2e67230b59719e56d">nn::CrossEntropy::MEAN</a></div><div class="ttdeci">@ MEAN</div><div class="ttdef"><b>Definition</b> Loss.hpp:14</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_a66479cf14574903516fdc5fd59b4b8b3ae3282ef2d73939de84601a2aabc567ad"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#a66479cf14574903516fdc5fd59b4b8b3ae3282ef2d73939de84601a2aabc567ad">nn::CrossEntropy::SUM</a></div><div class="ttdeci">@ SUM</div><div class="ttdef"><b>Definition</b> Loss.hpp:14</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_a8df82dc1e730e73cb3636d0d584158dc"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#a8df82dc1e730e73cb3636d0d584158dc">nn::CrossEntropy::reduction_</a></div><div class="ttdeci">Reduction reduction_</div><div class="ttdef"><b>Definition</b> Loss.hpp:53</div></div>
<div class="ttc" id="astructnn_1_1CrossEntropy_html_ac2c82ea85793511ae3c7a6e58961ba52"><div class="ttname"><a href="structnn_1_1CrossEntropy.html#ac2c82ea85793511ae3c7a6e58961ba52">nn::CrossEntropy::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> Loss.hpp:13</div></div>
<div class="ttc" id="astructnn_1_1DataTypeToEnum_html"><div class="ttname"><a href="structnn_1_1DataTypeToEnum.html">nn::DataTypeToEnum</a></div><div class="ttdef"><b>Definition</b> nn.hpp:135</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html"><div class="ttname"><a href="structnn_1_1Embedding.html">nn::Embedding</a></div><div class="ttdef"><b>Definition</b> nn.hpp:562</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a0836507be6dea19c0289e580e2fb8973"><div class="ttname"><a href="structnn_1_1Embedding.html#a0836507be6dea19c0289e580e2fb8973">nn::Embedding::NumActivations</a></div><div class="ttdeci">size_t NumActivations() const</div><div class="ttdef"><b>Definition</b> nn.hpp:598</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a0e3855fe03f02d5bf6cd047fe476258a"><div class="ttname"><a href="structnn_1_1Embedding.html#a0e3855fe03f02d5bf6cd047fe476258a">nn::Embedding::weight_</a></div><div class="ttdeci">std::unique_ptr&lt; Parameter &gt; weight_</div><div class="ttdef"><b>Definition</b> Embedding.hpp:57</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a17a1666754ba09e03c9073abc89e27e8"><div class="ttname"><a href="structnn_1_1Embedding.html#a17a1666754ba09e03c9073abc89e27e8">nn::Embedding::NumParameters</a></div><div class="ttdeci">size_t NumParameters() const</div><div class="ttdef"><b>Definition</b> nn.hpp:596</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a20ec286e805f73e6c796263abc4cbd6e"><div class="ttname"><a href="structnn_1_1Embedding.html#a20ec286e805f73e6c796263abc4cbd6e">nn::Embedding::embedding_dim_</a></div><div class="ttdeci">int embedding_dim_</div><div class="ttdef"><b>Definition</b> Embedding.hpp:56</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a427a7f4f7e77b6904e6fa19b373ebc34"><div class="ttname"><a href="structnn_1_1Embedding.html#a427a7f4f7e77b6904e6fa19b373ebc34">nn::Embedding::Backward</a></div><div class="ttdeci">void Backward(absl::Span&lt; const int &gt; idx, absl::Span&lt; const float &gt; grad_embedding)</div><div class="ttdef"><b>Definition</b> nn.hpp:580</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a63bb11f840116115c042f99771853944"><div class="ttname"><a href="structnn_1_1Embedding.html#a63bb11f840116115c042f99771853944">nn::Embedding::Embedding</a></div><div class="ttdeci">Embedding(int num_embeddings, int embedding_dim)</div><div class="ttdef"><b>Definition</b> nn.hpp:563</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a8669a3a9dadd00830d3d1d0b48a37789"><div class="ttname"><a href="structnn_1_1Embedding.html#a8669a3a9dadd00830d3d1d0b48a37789">nn::Embedding::Parameters</a></div><div class="ttdeci">void Parameters(std::vector&lt; Parameter * &gt; *parameters) const</div><div class="ttdef"><b>Definition</b> nn.hpp:600</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_a9aa76d7d0487450a2ca01c185b0375c1"><div class="ttname"><a href="structnn_1_1Embedding.html#a9aa76d7d0487450a2ca01c185b0375c1">nn::Embedding::num_embeddings_</a></div><div class="ttdeci">int num_embeddings_</div><div class="ttdef"><b>Definition</b> Embedding.hpp:55</div></div>
<div class="ttc" id="astructnn_1_1Embedding_html_ae46671667b089b91f58428338b7097a4"><div class="ttname"><a href="structnn_1_1Embedding.html#ae46671667b089b91f58428338b7097a4">nn::Embedding::Forward</a></div><div class="ttdeci">void Forward(absl::Span&lt; const int &gt; idx, absl::Span&lt; float &gt; embedding) const</div><div class="ttdef"><b>Definition</b> nn.hpp:570</div></div>
<div class="ttc" id="astructnn_1_1EnumToDataType_html"><div class="ttname"><a href="structnn_1_1EnumToDataType.html">nn::EnumToDataType</a></div><div class="ttdef"><b>Definition</b> nn.hpp:142</div></div>
<div class="ttc" id="astructnn_1_1IsValidDataType_html"><div class="ttname"><a href="structnn_1_1IsValidDataType.html">nn::IsValidDataType</a></div><div class="ttdef"><b>Definition</b> nn.hpp:130</div></div>
<div class="ttc" id="astructnn_1_1Linear_html"><div class="ttname"><a href="structnn_1_1Linear.html">nn::Linear</a></div><div class="ttdef"><b>Definition</b> nn.hpp:457</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a08e89584cfce3229c870cb1048261bd0"><div class="ttname"><a href="structnn_1_1Linear.html#a08e89584cfce3229c870cb1048261bd0">nn::Linear::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> Linear.hpp:14</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a13d4f763b63f1e09d54a491a0cccfe6c"><div class="ttname"><a href="structnn_1_1Linear.html#a13d4f763b63f1e09d54a491a0cccfe6c">nn::Linear::bias_</a></div><div class="ttdeci">std::unique_ptr&lt; Parameter &gt; bias_</div><div class="ttdef"><b>Definition</b> Linear.hpp:115</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a2f1e0f7cef394d2a5f3988ade39de320"><div class="ttname"><a href="structnn_1_1Linear.html#a2f1e0f7cef394d2a5f3988ade39de320">nn::Linear::Parameters</a></div><div class="ttdeci">void Parameters(std::vector&lt; Parameter * &gt; *parameters) const</div><div class="ttdef"><b>Definition</b> nn.hpp:548</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a34d599cf91de5e85d30162cecab1201d"><div class="ttname"><a href="structnn_1_1Linear.html#a34d599cf91de5e85d30162cecab1201d">nn::Linear::Linear</a></div><div class="ttdeci">Linear(int in_features, int out_features, bool bias=true)</div><div class="ttdef"><b>Definition</b> nn.hpp:460</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a409875da04ee814f1da7847a261b0a8a"><div class="ttname"><a href="structnn_1_1Linear.html#a409875da04ee814f1da7847a261b0a8a">nn::Linear::NumParameters</a></div><div class="ttdeci">size_t NumParameters() const</div><div class="ttdef"><b>Definition</b> nn.hpp:537</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a604a0a510c6eed24be8b31b6d1e131b1"><div class="ttname"><a href="structnn_1_1Linear.html#a604a0a510c6eed24be8b31b6d1e131b1">nn::Linear::NumActivations</a></div><div class="ttdeci">size_t NumActivations() const</div><div class="ttdef"><b>Definition</b> nn.hpp:546</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a64e6ffe3fbc3c76826b715609a105b22"><div class="ttname"><a href="structnn_1_1Linear.html#a64e6ffe3fbc3c76826b715609a105b22">nn::Linear::Forward</a></div><div class="ttdeci">void Forward(typename TTypes&lt; T &gt;::ConstMatrix x, typename TTypes&lt; T &gt;::Matrix y) const</div><div class="ttdef"><b>Definition</b> nn.hpp:474</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_a72bd5097d6212d9c40124b2a9112aea7"><div class="ttname"><a href="structnn_1_1Linear.html#a72bd5097d6212d9c40124b2a9112aea7">nn::Linear::has_bias_</a></div><div class="ttdeci">bool has_bias_</div><div class="ttdef"><b>Definition</b> Linear.hpp:111</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_aabbd0988c06e326f03daa1be44de1124"><div class="ttname"><a href="structnn_1_1Linear.html#aabbd0988c06e326f03daa1be44de1124">nn::Linear::weight_</a></div><div class="ttdeci">std::unique_ptr&lt; Parameter &gt; weight_</div><div class="ttdef"><b>Definition</b> Linear.hpp:114</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_ab98234ba76a2c699c39cc42bf6039d47"><div class="ttname"><a href="structnn_1_1Linear.html#ab98234ba76a2c699c39cc42bf6039d47">nn::Linear::out_features_</a></div><div class="ttdeci">int out_features_</div><div class="ttdef"><b>Definition</b> Linear.hpp:113</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_adc5b2d2b9d62d9dca412db85ee72d7e1"><div class="ttname"><a href="structnn_1_1Linear.html#adc5b2d2b9d62d9dca412db85ee72d7e1">nn::Linear::Backward</a></div><div class="ttdeci">void Backward(typename TTypes&lt; T &gt;::ConstMatrix x, typename TTypes&lt; T &gt;::ConstMatrix y_grad, typename TTypes&lt; T &gt;::Matrix x_grad)</div><div class="ttdef"><b>Definition</b> nn.hpp:497</div></div>
<div class="ttc" id="astructnn_1_1Linear_html_ae00df6b4cbb5e5f6f47f710fdc2c3c70"><div class="ttname"><a href="structnn_1_1Linear.html#ae00df6b4cbb5e5f6f47f710fdc2c3c70">nn::Linear::in_features_</a></div><div class="ttdeci">int in_features_</div><div class="ttdef"><b>Definition</b> Linear.hpp:112</div></div>
<div class="ttc" id="astructnn_1_1MatMul_html"><div class="ttname"><a href="structnn_1_1MatMul.html">nn::MatMul</a></div><div class="ttdef"><b>Definition</b> nn.hpp:381</div></div>
<div class="ttc" id="astructnn_1_1MatMul_html_a64937ece43bd2e55440ff29d940cdb9a"><div class="ttname"><a href="structnn_1_1MatMul.html#a64937ece43bd2e55440ff29d940cdb9a">nn::MatMul::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> MatMul.hpp:14</div></div>
<div class="ttc" id="astructnn_1_1MatMul_html_a8d05ee55fe5c544993b4371333300e78"><div class="ttname"><a href="structnn_1_1MatMul.html#a8d05ee55fe5c544993b4371333300e78">nn::MatMul::Forward</a></div><div class="ttdeci">static void Forward(typename TTypes&lt; T &gt;::ConstMatrix x1, typename TTypes&lt; T &gt;::ConstMatrix x2, typename TTypes&lt; T &gt;::Matrix y, T scale=1.0f)</div><div class="ttdef"><b>Definition</b> nn.hpp:384</div></div>
<div class="ttc" id="astructnn_1_1MatMul_html_aeb87efe916cb0309e67f3957ba6628a1"><div class="ttname"><a href="structnn_1_1MatMul.html#aeb87efe916cb0309e67f3957ba6628a1">nn::MatMul::Backward</a></div><div class="ttdeci">static void Backward(typename TTypes&lt; T &gt;::ConstMatrix x1, typename TTypes&lt; T &gt;::ConstMatrix x2, typename TTypes&lt; T &gt;::ConstMatrix y_grad, typename TTypes&lt; T &gt;::Matrix x1_grad, typename TTypes&lt; T &gt;::Matrix x2_grad, T scale=1.0)</div><div class="ttdef"><b>Definition</b> nn.hpp:399</div></div>
<div class="ttc" id="astructnn_1_1NewGELU_html"><div class="ttname"><a href="structnn_1_1NewGELU.html">nn::NewGELU</a></div><div class="ttdef"><b>Definition</b> nn.hpp:612</div></div>
<div class="ttc" id="astructnn_1_1NewGELU_html_a61bfcf96b22838809e7ed1c217df351f"><div class="ttname"><a href="structnn_1_1NewGELU.html#a61bfcf96b22838809e7ed1c217df351f">nn::NewGELU::Backward</a></div><div class="ttdeci">static void Backward(typename TTypes&lt; T &gt;::ConstFlat x, typename TTypes&lt; T &gt;::ConstFlat y_grad, typename TTypes&lt; T &gt;::Flat x_grad)</div><div class="ttdef"><b>Definition</b> nn.hpp:626</div></div>
<div class="ttc" id="astructnn_1_1NewGELU_html_aa83faf7441c0ebe6c33fd3f7610eb1dc"><div class="ttname"><a href="structnn_1_1NewGELU.html#aa83faf7441c0ebe6c33fd3f7610eb1dc">nn::NewGELU::Forward</a></div><div class="ttdeci">static void Forward(typename TTypes&lt; T &gt;::ConstFlat x, typename TTypes&lt; T &gt;::Flat y)</div><div class="ttdef"><b>Definition</b> nn.hpp:615</div></div>
<div class="ttc" id="astructnn_1_1NewGELU_html_aea252245f5f7a07d0b5dcb8156e14a03"><div class="ttname"><a href="structnn_1_1NewGELU.html#aea252245f5f7a07d0b5dcb8156e14a03">nn::NewGELU::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> Parameter.hpp:412</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html"><div class="ttname"><a href="structnn_1_1Parameter.html">nn::Parameter</a></div><div class="ttdef"><b>Definition</b> nn.hpp:165</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a0225855097608608bd9d4e1df866126c"><div class="ttname"><a href="structnn_1_1Parameter.html#a0225855097608608bd9d4e1df866126c">nn::Parameter::tensor_3d</a></div><div class="ttdeci">TTypes&lt; T, 3 &gt;::Tensor tensor_3d(int dim0, int dim1, int dim2) const</div><div class="ttdef"><b>Definition</b> nn.hpp:266</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a1510411a8f4221a6e163896c7e586f90"><div class="ttname"><a href="structnn_1_1Parameter.html#a1510411a8f4221a6e163896c7e586f90">nn::Parameter::const_matrix_grad</a></div><div class="ttdeci">TTypes&lt; T &gt;::ConstMatrix const_matrix_grad(int rows, int cols) const</div><div class="ttdef"><b>Definition</b> nn.hpp:312</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a18e03a33c68df7e4b79cb02e9d25aed8"><div class="ttname"><a href="structnn_1_1Parameter.html#a18e03a33c68df7e4b79cb02e9d25aed8">nn::Parameter::operator=</a></div><div class="ttdeci">Parameter &amp; operator=(const Parameter &amp;)=delete</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a1ee1215e818b6f398934b9813c0fa03d"><div class="ttname"><a href="structnn_1_1Parameter.html#a1ee1215e818b6f398934b9813c0fa03d">nn::Parameter::LazyAllocate</a></div><div class="ttdeci">void LazyAllocate(int num_element)</div><div class="ttdef"><b>Definition</b> Parameter.hpp:191</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a26d35841294de83ed2f9a64525d1420b"><div class="ttname"><a href="structnn_1_1Parameter.html#a26d35841294de83ed2f9a64525d1420b">nn::Parameter::span_grad</a></div><div class="ttdeci">absl::Span&lt; T &gt; span_grad() const</div><div class="ttdef"><b>Definition</b> nn.hpp:236</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a2fe94f0c8a72286208dbd447419f7fd0"><div class="ttname"><a href="structnn_1_1Parameter.html#a2fe94f0c8a72286208dbd447419f7fd0">nn::Parameter::const_tensor_4d</a></div><div class="ttdeci">TTypes&lt; T, 4 &gt;::ConstTensor const_tensor_4d(int dim0, int dim1, int dim2, int dim3) const</div><div class="ttdef"><b>Definition</b> nn.hpp:287</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a41ce5efd7f501301e59858c3edd7904a"><div class="ttname"><a href="structnn_1_1Parameter.html#a41ce5efd7f501301e59858c3edd7904a">nn::Parameter::grad</a></div><div class="ttdeci">T * grad() const</div><div class="ttdef"><b>Definition</b> nn.hpp:225</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a52db062016881a2cb90535351c4377ef"><div class="ttname"><a href="structnn_1_1Parameter.html#a52db062016881a2cb90535351c4377ef">nn::Parameter::ZeroGrad</a></div><div class="ttdeci">void ZeroGrad()</div><div class="ttdef"><b>Definition</b> nn.hpp:213</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a57425fbc922f81c2d9ef81287c29b24e"><div class="ttname"><a href="structnn_1_1Parameter.html#a57425fbc922f81c2d9ef81287c29b24e">nn::Parameter::matrix</a></div><div class="ttdeci">TTypes&lt; T &gt;::Matrix matrix(int rows, int cols) const</div><div class="ttdef"><b>Definition</b> nn.hpp:253</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a583c2b74827af48d9677855299ba15cb"><div class="ttname"><a href="structnn_1_1Parameter.html#a583c2b74827af48d9677855299ba15cb">nn::Parameter::Parameter</a></div><div class="ttdeci">Parameter(const Parameter &amp;)=delete</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a64181c4853cb79169680bbf4bce05f3d"><div class="ttname"><a href="structnn_1_1Parameter.html#a64181c4853cb79169680bbf4bce05f3d">nn::Parameter::const_tensor_4d_grad</a></div><div class="ttdeci">TTypes&lt; T, 4 &gt;::ConstTensor const_tensor_4d_grad(int dim0, int dim1, int dim2, int dim3) const</div><div class="ttdef"><b>Definition</b> nn.hpp:342</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a6d0ae2b005bfc890d7d8b72798dcc43a"><div class="ttname"><a href="structnn_1_1Parameter.html#a6d0ae2b005bfc890d7d8b72798dcc43a">nn::Parameter::const_flat_grad</a></div><div class="ttdeci">TTypes&lt; T &gt;::ConstFlat const_flat_grad() const</div><div class="ttdef"><b>Definition</b> nn.hpp:300</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a6f0e1ddc221a505c43c7abf5bcf439ee"><div class="ttname"><a href="structnn_1_1Parameter.html#a6f0e1ddc221a505c43c7abf5bcf439ee">nn::Parameter::flat</a></div><div class="ttdeci">TTypes&lt; T &gt;::Flat flat() const</div><div class="ttdef"><b>Definition</b> nn.hpp:242</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a7c03f7343425f14757e8921a2cc5d13d"><div class="ttname"><a href="structnn_1_1Parameter.html#a7c03f7343425f14757e8921a2cc5d13d">nn::Parameter::const_tensor_3d</a></div><div class="ttdeci">TTypes&lt; T, 3 &gt;::ConstTensor const_tensor_3d(int dim0, int dim1, int dim2) const</div><div class="ttdef"><b>Definition</b> nn.hpp:272</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a7f4e7a8af36cef820ae8c05c943af2e5"><div class="ttname"><a href="structnn_1_1Parameter.html#a7f4e7a8af36cef820ae8c05c943af2e5">nn::Parameter::data</a></div><div class="ttdeci">T * data() const</div><div class="ttdef"><b>Definition</b> nn.hpp:220</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a83ee4857383ef5f5e62de7529498d43e"><div class="ttname"><a href="structnn_1_1Parameter.html#a83ee4857383ef5f5e62de7529498d43e">nn::Parameter::tensor_3d_grad</a></div><div class="ttdeci">TTypes&lt; T, 3 &gt;::Tensor tensor_3d_grad(int dim0, int dim1, int dim2) const</div><div class="ttdef"><b>Definition</b> nn.hpp:319</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a96fd7a8f8ff1890afc82c16006105642"><div class="ttname"><a href="structnn_1_1Parameter.html#a96fd7a8f8ff1890afc82c16006105642">nn::Parameter::tensor_4d</a></div><div class="ttdeci">TTypes&lt; T, 4 &gt;::Tensor tensor_4d(int dim0, int dim1, int dim2, int dim3) const</div><div class="ttdef"><b>Definition</b> nn.hpp:280</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_a9b7a7795983465be2eb5cb5546cd63a3"><div class="ttname"><a href="structnn_1_1Parameter.html#a9b7a7795983465be2eb5cb5546cd63a3">nn::Parameter::matrix_grad</a></div><div class="ttdeci">TTypes&lt; T &gt;::Matrix matrix_grad(int rows, int cols) const</div><div class="ttdef"><b>Definition</b> nn.hpp:306</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_abe781e9cb2ab94df0e45ce4adf20d56d"><div class="ttname"><a href="structnn_1_1Parameter.html#abe781e9cb2ab94df0e45ce4adf20d56d">nn::Parameter::span</a></div><div class="ttdeci">absl::Span&lt; T &gt; span() const</div><div class="ttdef"><b>Definition</b> nn.hpp:230</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_ac0ee4086c327b580089e3df17177c295"><div class="ttname"><a href="structnn_1_1Parameter.html#ac0ee4086c327b580089e3df17177c295">nn::Parameter::const_flat</a></div><div class="ttdeci">TTypes&lt; T &gt;::ConstFlat const_flat() const</div><div class="ttdef"><b>Definition</b> nn.hpp:247</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_aca04f2db8d48672f0d9ffaff4cd04341"><div class="ttname"><a href="structnn_1_1Parameter.html#aca04f2db8d48672f0d9ffaff4cd04341">nn::Parameter::~Parameter</a></div><div class="ttdeci">~Parameter()</div><div class="ttdef"><b>Definition</b> nn.hpp:179</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_ad146b3bd6d2d220409ea0cf5aebfe2eb"><div class="ttname"><a href="structnn_1_1Parameter.html#ad146b3bd6d2d220409ea0cf5aebfe2eb">nn::Parameter::ZeroData</a></div><div class="ttdeci">void ZeroData()</div><div class="ttdef"><b>Definition</b> nn.hpp:207</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_ad1e84918801072e188a3c683f668e5cf"><div class="ttname"><a href="structnn_1_1Parameter.html#ad1e84918801072e188a3c683f668e5cf">nn::Parameter::tensor_4d_grad</a></div><div class="ttdeci">TTypes&lt; T, 4 &gt;::Tensor tensor_4d_grad(int dim0, int dim1, int dim2, int dim3) const</div><div class="ttdef"><b>Definition</b> nn.hpp:334</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_ad48cb3449bf14e55ef9ee3bbc1185040"><div class="ttname"><a href="structnn_1_1Parameter.html#ad48cb3449bf14e55ef9ee3bbc1185040">nn::Parameter::Parameter</a></div><div class="ttdeci">Parameter(DataType dtype, int64_t num_element=0)</div><div class="ttdef"><b>Definition</b> nn.hpp:169</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_ad9ef295d080c627b955acbf5b25b78a9"><div class="ttname"><a href="structnn_1_1Parameter.html#ad9ef295d080c627b955acbf5b25b78a9">nn::Parameter::const_matrix</a></div><div class="ttdeci">TTypes&lt; T &gt;::ConstMatrix const_matrix(int rows, int cols) const</div><div class="ttdef"><b>Definition</b> nn.hpp:259</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_adc5d7e335fd359c4abaa49579c66bd72"><div class="ttname"><a href="structnn_1_1Parameter.html#adc5d7e335fd359c4abaa49579c66bd72">nn::Parameter::flat_grad</a></div><div class="ttdeci">TTypes&lt; T &gt;::Flat flat_grad() const</div><div class="ttdef"><b>Definition</b> nn.hpp:295</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_ae5946d86c24b338dc5c0592637a97259"><div class="ttname"><a href="structnn_1_1Parameter.html#ae5946d86c24b338dc5c0592637a97259">nn::Parameter::LazyAllocateGradient</a></div><div class="ttdeci">void LazyAllocateGradient()</div><div class="ttdef"><b>Definition</b> nn.hpp:199</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_ae9da6b86774d2ff46dfbd89c432c12e4"><div class="ttname"><a href="structnn_1_1Parameter.html#ae9da6b86774d2ff46dfbd89c432c12e4">nn::Parameter::const_tensor_3d_grad</a></div><div class="ttdeci">TTypes&lt; T, 3 &gt;::ConstTensor const_tensor_3d_grad(int dim0, int dim1, int dim2) const</div><div class="ttdef"><b>Definition</b> nn.hpp:326</div></div>
<div class="ttc" id="astructnn_1_1Parameter_html_af39913537c8c3d6b71377c3df9333b56"><div class="ttname"><a href="structnn_1_1Parameter.html#af39913537c8c3d6b71377c3df9333b56">nn::Parameter::size</a></div><div class="ttdeci">int64_t size() const</div><div class="ttdef"><b>Definition</b> nn.hpp:188</div></div>
<div class="ttc" id="astructnn_1_1Residual_html"><div class="ttname"><a href="structnn_1_1Residual.html">nn::Residual</a></div><div class="ttdef"><b>Definition</b> nn.hpp:433</div></div>
<div class="ttc" id="astructnn_1_1Residual_html_a4891550c91057f4f56dd81242f62893d"><div class="ttname"><a href="structnn_1_1Residual.html#a4891550c91057f4f56dd81242f62893d">nn::Residual::Forward</a></div><div class="ttdeci">static void Forward(typename TTypes&lt; T &gt;::ConstFlat x, typename TTypes&lt; T &gt;::ConstFlat Fx, typename TTypes&lt; T &gt;::Flat Hx)</div><div class="ttdef"><b>Definition</b> nn.hpp:436</div></div>
<div class="ttc" id="astructnn_1_1Residual_html_a6058419c871cad6d7ec56982369bc57a"><div class="ttname"><a href="structnn_1_1Residual.html#a6058419c871cad6d7ec56982369bc57a">nn::Residual::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> Parameter.hpp:383</div></div>
<div class="ttc" id="astructnn_1_1Residual_html_a99d49a6ebe5268051e6de48f423e2a43"><div class="ttname"><a href="structnn_1_1Residual.html#a99d49a6ebe5268051e6de48f423e2a43">nn::Residual::Backward</a></div><div class="ttdeci">static void Backward(typename TTypes&lt; T &gt;::ConstFlat Hx_grad, typename TTypes&lt; T &gt;::Flat x_grad, typename TTypes&lt; T &gt;::Flat Fx_grad)</div><div class="ttdef"><b>Definition</b> nn.hpp:446</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html">nn::SoftmaxCrossEntropy</a></div><div class="ttdef"><b>Definition</b> nn.hpp:730</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a353b6bc3af73be364a53c3ae80019bd3"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a353b6bc3af73be364a53c3ae80019bd3">nn::SoftmaxCrossEntropy::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:93</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a60b41ca5338568fc097834fbaabe8ec0"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">nn::SoftmaxCrossEntropy::reduction_</a></div><div class="ttdeci">Reduction reduction_</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:190</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a61c0fc7c4f30c38c37b2a69353aebfb8"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a61c0fc7c4f30c38c37b2a69353aebfb8">nn::SoftmaxCrossEntropy::SoftmaxCrossEntropy</a></div><div class="ttdeci">SoftmaxCrossEntropy(Reduction reduction=Reduction::MEAN)</div><div class="ttdef"><b>Definition</b> nn.hpp:734</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a7688dce4252afd47dbb64a0b5717ea2c"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a7688dce4252afd47dbb64a0b5717ea2c">nn::SoftmaxCrossEntropy::ForwardAndBackward</a></div><div class="ttdeci">static void ForwardAndBackward(typename TTypes&lt; T &gt;::ConstMatrix logits, typename TTypes&lt; T &gt;::ConstMatrix labels, typename TTypes&lt; T &gt;::Flat scratch, typename TTypes&lt; T &gt;::Flat loss, typename TTypes&lt; T &gt;::Matrix logit_grad)</div><div class="ttdef"><b>Definition</b> nn.hpp:781</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a8f693b30c7b9e1c382dce3cdd77a8b04"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">nn::SoftmaxCrossEntropy::Reduction</a></div><div class="ttdeci">Reduction</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:94</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a8f693b30c7b9e1c382dce3cdd77a8b04a44fe5ec5ac95c2fce33759616a32a6ad"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04a44fe5ec5ac95c2fce33759616a32a6ad">nn::SoftmaxCrossEntropy::SUM</a></div><div class="ttdeci">@ SUM</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:94</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a8f693b30c7b9e1c382dce3cdd77a8b04add36ad20b6e6cbc891022762da1b385d"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04add36ad20b6e6cbc891022762da1b385d">nn::SoftmaxCrossEntropy::MEAN</a></div><div class="ttdeci">@ MEAN</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:94</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_abd096903b589b4f9575bfca0e5b7b49d"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#abd096903b589b4f9575bfca0e5b7b49d">nn::SoftmaxCrossEntropy::Backward</a></div><div class="ttdeci">void Backward(typename TTypes&lt; T &gt;::ConstMatrix probs, absl::Span&lt; const int &gt; targets, typename TTypes&lt; T &gt;::Matrix logits_grad)</div><div class="ttdef"><b>Definition</b> nn.hpp:760</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_afb6a8fe2404484125128f5b2cafe7806"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#afb6a8fe2404484125128f5b2cafe7806">nn::SoftmaxCrossEntropy::Forward</a></div><div class="ttdeci">void Forward(typename TTypes&lt; T &gt;::ConstMatrix logits, absl::Span&lt; const int &gt; targets, typename TTypes&lt; T &gt;::Matrix probs, float *loss)</div><div class="ttdef"><b>Definition</b> nn.hpp:737</div></div>
<div class="ttc" id="astructnn_1_1Softmax_html"><div class="ttname"><a href="structnn_1_1Softmax.html">nn::Softmax</a></div><div class="ttdef"><b>Definition</b> nn.hpp:652</div></div>
<div class="ttc" id="astructnn_1_1Softmax_html_a1552ecc513a69adec694e31a57bc926d"><div class="ttname"><a href="structnn_1_1Softmax.html#a1552ecc513a69adec694e31a57bc926d">nn::Softmax::Backward</a></div><div class="ttdeci">static void Backward(typename TTypes&lt; T &gt;::ConstMatrix y, typename TTypes&lt; T &gt;::ConstMatrix y_grad, typename TTypes&lt; T &gt;::Matrix x_grad)</div><div class="ttdef"><b>Definition</b> nn.hpp:678</div></div>
<div class="ttc" id="astructnn_1_1Softmax_html_ad89595ce55976d7e45283370ca51fb5c"><div class="ttname"><a href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">nn::Softmax::Forward</a></div><div class="ttdeci">static void Forward(typename TTypes&lt; T &gt;::ConstMatrix x, typename TTypes&lt; T &gt;::Matrix y)</div><div class="ttdef"><b>Definition</b> nn.hpp:655</div></div>
<div class="ttc" id="astructnn_1_1Softmax_html_af7722532871a3341255166920486e0aa"><div class="ttname"><a href="structnn_1_1Softmax.html#af7722532871a3341255166920486e0aa">nn::Softmax::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:14</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
