<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: nn/SoftMax.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_304cc21f2f2363348d92f15d6aec0cb5.html">nn</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="headertitle"><div class="title">SoftMax.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="SoftMax_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="preprocessor">#ifndef LLM_CPP__SOFTMAX_HPP_</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="preprocessor">#define LLM_CPP__SOFTMAX_HPP_</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span> </div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="preprocessor">#include &quot;<a class="code" href="tensor_2tensor__util_8hpp.html">tensor/tensor_util.hpp</a>&quot;</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="preprocessor">#include &quot;absl/log/check.h&quot;</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="preprocessor">#include &quot;absl/types/span.h&quot;</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="preprocessor">#include &quot;<a class="code" href="Parameter_8hpp.html">Parameter.hpp</a>&quot;</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span> </div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span> </div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacenn.html">nn</a> {</div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span> </div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="keyword">struct </span>Softmax {</div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno"><a class="line" href="structnn_1_1Softmax.html#af7722532871a3341255166920486e0aa">   14</a></span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1Softmax.html#af7722532871a3341255166920486e0aa">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span> </div>
<div class="foldopen" id="foldopen00016" data-start="{" data-end="}">
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno"><a class="line" href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">   16</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> x,</div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span>                      <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> y) {</div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span>    <span class="comment">// x: [B, D], y: [B, D]</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(0), y.dimension(0));</div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(x.dimension(1), y.dimension(1));</div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span> </div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span>    <span class="keywordtype">int</span> batch_size = x.dimension(0), num_class = x.dimension(1);</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 1&gt;</a> along_class = {1};</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> batch_by_one = {batch_size, 1};</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> one_by_class = {1, num_class};</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span> </div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span>    y.device(g_device) = (x - x.maximum(along_class)</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span>                                  .eval()</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span>                                  .reshape(batch_by_one)</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span>                                  .broadcast(one_by_class))</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>                             .exp();</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>    y.device(g_device) = y * y.sum(along_class)</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span>                                 .inverse()</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>                                 .eval()</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>                                 .reshape(batch_by_one)</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span>                                 .broadcast(one_by_class);</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>  }</div>
</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span> </div>
<div class="foldopen" id="foldopen00039" data-start="{" data-end="}">
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno"><a class="line" href="structnn_1_1Softmax.html#a1552ecc513a69adec694e31a57bc926d">   39</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1Softmax.html#a1552ecc513a69adec694e31a57bc926d">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> y,</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> y_grad,</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>                       <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> x_grad) {</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>    <span class="comment">// y:[B, D], y_grad: [B, D], x_grad: [B, D]</span></div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>    <span class="keywordtype">int</span> B = y.dimension(0), D = y.dimension(1);</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; B == x_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(D == y_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1) &amp;&amp; D == x_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span> </div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>    <span class="comment">// Using alternative formula:</span></div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>    <span class="comment">// dL/dx = dL/dy * y - sum(dL/dy * y) * y</span></div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>    <span class="comment">//    = (dL/dy - sum(dL/dy * y)) * y</span></div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>    <span class="keywordtype">int</span> batch_size = y.dimension(0), num_class = y.dimension(1);</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> batch_by_one = {batch_size, 1};</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> one_by_class = {1, num_class};</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 1&gt;</a> along_class = {1};</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>    <span class="keyword">auto</span> dyy = y_grad * y;</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>    <span class="keyword">auto</span> sum = dyy.sum(along_class).reshape(batch_by_one);</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>    <span class="keyword">auto</span> sub = y_grad - sum.broadcast(one_by_class);</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>    x_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) += sub * y;</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span> </div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>    <span class="comment">/*</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span><span class="comment">    // dy_j / dx_i = S_i(1 - S_j) for i==j</span></div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="comment">    //             = -S_j*S_i     for i!=j</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span><span class="comment">    // dL/dx_i = \sum_j dL/dy_j * dy_j / dx_i</span></div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span><span class="comment">    auto fn = [D, &amp;x_grad, &amp;y_grad, &amp;y](int begin, int end) {</span></div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span><span class="comment">      for (int b = begin; b &lt; end; ++b) {</span></div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span><span class="comment">        float* x_grad_b = x_grad.data() + b * D;</span></div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span><span class="comment">        float* y_grad_b = y_grad.data() + b * D;</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span><span class="comment">        float* y_b = y.data() + b * D;</span></div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span><span class="comment">        for (int i = 0; i &lt; D; ++i) {</span></div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span><span class="comment">          for (int j = 0; j &lt; D; ++j) {</span></div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span><span class="comment">            float indicator = i == j ? 1.0f : 0.0f;</span></div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span><span class="comment">            //            x_grad(b, i) += y_grad(b, j) * y(b, i) * (indicator -</span></div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span><span class="comment">            //            y(b, j));</span></div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span><span class="comment">            x_grad_b[i] += y_grad_b[j] * y_b[i] * (indicator - y_b[j]);</span></div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span><span class="comment">          }</span></div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span><span class="comment">        }</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span><span class="comment">      }</span></div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span><span class="comment">    };</span></div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span><span class="comment"></span> </div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span><span class="comment">    int thread_num = g_cpu_device.numThreads();</span></div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span><span class="comment">    Eigen::Barrier barrier(thread_num);</span></div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span><span class="comment">    for (int t = 0; t &lt; thread_num; ++t) {</span></div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span><span class="comment">      auto range = SplitRange(B, t, thread_num);</span></div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span><span class="comment">      g_cpu_device.enqueue_with_barrier(&amp;barrier, fn, range.first,</span></div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span><span class="comment">                                        range.second);</span></div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span><span class="comment">    }</span></div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span><span class="comment">    barrier.Wait();</span></div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span><span class="comment">    */</span></div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>  }</div>
</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>};</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span> </div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span><span class="comment">//From what I could see, this only uses the Eigen library ~NR</span></div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span><span class="keyword">struct </span>SoftmaxCrossEntropy {</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a353b6bc3af73be364a53c3ae80019bd3">   93</a></span>  <span class="keyword">using </span><a class="code hl_typedef" href="structnn_1_1SoftmaxCrossEntropy.html#a353b6bc3af73be364a53c3ae80019bd3">T</a> = <a class="code hl_typedef" href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a>;</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04add36ad20b6e6cbc891022762da1b385d">   94</a></span>  <span class="keyword">enum</span> <a class="code hl_enumeration" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">Reduction</a> { <a class="code hl_enumvalue" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04add36ad20b6e6cbc891022762da1b385d">MEAN</a>, <a class="code hl_enumvalue" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04a44fe5ec5ac95c2fce33759616a32a6ad">SUM</a> };</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span> </div>
<div class="foldopen" id="foldopen00096" data-start="{" data-end="}">
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a61c0fc7c4f30c38c37b2a69353aebfb8">   96</a></span>  <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#a61c0fc7c4f30c38c37b2a69353aebfb8">SoftmaxCrossEntropy</a>(<a class="code hl_enumeration" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">Reduction</a> reduction = Reduction::MEAN)</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>      : <a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a>(reduction) {}</div>
</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span> </div>
<div class="foldopen" id="foldopen00099" data-start="{" data-end="}">
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#afb6a8fe2404484125128f5b2cafe7806">   99</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#afb6a8fe2404484125128f5b2cafe7806">Forward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> logits,</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>               <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> targets, <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> probs,</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>               <span class="keywordtype">float</span>* loss) {</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>    <span class="comment">// logits: [B, C], targets: [B,], probs:[B, C], loss: scalar</span></div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>    <span class="keywordtype">int</span> B = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>() &amp;&amp; B == probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>, probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span> </div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>    <span class="comment">// apply softmax to convert logits to (normalized) probabilities</span></div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>    <a class="code hl_function" href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">Softmax::Forward</a>(logits, probs);</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span> </div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>    <span class="comment">// targets: [B,]</span></div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>    *loss = 0.0f;</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a> &lt; targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>(); ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>) {</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>      <span class="keywordtype">int</span> ix = targets[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>];</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>      *loss += -std::log(probs(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a>, ix));</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>    }</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span> </div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a> == Reduction::MEAN) {</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>      *loss /= <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(B);</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>    }</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>  }</div>
</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span> </div>
<div class="foldopen" id="foldopen00122" data-start="{" data-end="}">
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#abd096903b589b4f9575bfca0e5b7b49d">  122</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#abd096903b589b4f9575bfca0e5b7b49d">Backward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> probs,</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>                <a class="code hl_class" href="classabsl_1_1Span.html">absl::Span&lt;const int&gt;</a> targets,</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>                <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> logits_grad) {</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>    <span class="comment">// probs: [B, C], targets: [B,]</span></div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>    <span class="comment">// logits_grad: [B, C]</span></div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>    <span class="keywordtype">int</span> B = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = probs.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == targets.<a class="code hl_function" href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">size</a>() &amp;&amp; B == logits_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0));</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(<a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>, logits_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span> </div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>    <span class="keywordtype">float</span> factor =</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>        <a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a> == Reduction::MEAN ? 1.0f / <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(B) : 1.0f;</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span> </div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a> = 0; <a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a> &lt; B; ++<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>) {</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>      <span class="keywordtype">int</span> ix = targets[<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>];</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>; ++c) {</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>        <span class="keywordtype">float</span> indicator = c == ix ? 1.0f : 0.0f;</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>        logits_grad(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>, c) += (probs(<a class="code hl_variable" href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a>, c) - indicator) * factor;</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>      }</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>    }</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>  }</div>
</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span> </div>
<div class="foldopen" id="foldopen00143" data-start="{" data-end="}">
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a7688dce4252afd47dbb64a0b5717ea2c">  143</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structnn_1_1SoftmaxCrossEntropy.html#a7688dce4252afd47dbb64a0b5717ea2c">ForwardAndBackward</a>(<span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> logits,</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::ConstMatrix</a> labels,</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> scratch,</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Flat</a> loss,</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>                                 <span class="keyword">typename</span> <a class="code hl_class" href="classEigen_1_1TensorMap.html">TTypes&lt;T&gt;::Matrix</a> logit_grad) {</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>    <span class="comment">// logits: [B, C], targets: [B,], probs:[B, C], loss: scalar</span></div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>    <span class="keywordtype">int</span> B = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0), <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> = logits.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1);</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == labels.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> == labels.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a>(B == logit_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(0) &amp;&amp; <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a> == logit_grad.<a class="code hl_function" href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">dimension</a>(1));</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(B, scratch.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>    <a class="code hl_define" href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a>(B, loss.<a class="code hl_function" href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">size</a>());</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span> </div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> batch_size = B, num_class = <a class="code hl_define" href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a>;</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 1&gt;</a> along_class = {1};</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> batch_by_one = {batch_size, 1};</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>    <a class="code hl_class" href="classEigen_1_1array.html">Eigen::array&lt;Eigen::Index, 2&gt;</a> one_by_class = {1, num_class};</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span> </div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>    <span class="comment">// max_logits along classes.</span></div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>    scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) = logits.maximum(along_class);</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span> </div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>    <span class="comment">// logits - max_logits.</span></div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>    logit_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) =</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>        logits - scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#adc5c658be289d8944ca3c8e7a2fac1f7">reshape</a>(batch_by_one).broadcast(one_by_class);</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span> </div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>    <span class="comment">// sum(exp(logits - max_logits)) along classes.</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>    scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) = logit_grad.exp().sum(along_class);</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span> </div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>    <span class="comment">// NOTE: Eigen on GPU dispatches to an optimized implementation</span></div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>    <span class="comment">// for an expression of the form lhs = rhs.sum().</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>    <span class="comment">// lhs = -rhs.sum() doesn&#39;t match the above pattern, so folding in the</span></div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>    <span class="comment">// negation before calling sum().</span></div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>    <span class="comment">//  sum(-labels *</span></div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>    <span class="comment">//     ((logits - max_logits) - log(sum(exp(logits - max_logits)))))</span></div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>    <span class="comment">//  along classes</span></div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>    loss.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) =</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>        (labels * (scratch.log().reshape(batch_by_one).broadcast(one_by_class) -</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>                   logit_grad))</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>            .sum(along_class);</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span> </div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>    <span class="comment">// backprop: prob - labels, where</span></div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>    <span class="comment">//   prob = exp(logits - max_logits) / sum(exp(logits - max_logits))</span></div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>    logit_grad.<a class="code hl_function" href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">device</a>(g_device) =</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>        (logit_grad.exp() /</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>         scratch.<a class="code hl_function" href="classEigen_1_1TensorBase.html#adc5c658be289d8944ca3c8e7a2fac1f7">reshape</a>(batch_by_one).broadcast(one_by_class)) -</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>        labels;</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>  }</div>
</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span> </div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno"><a class="line" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">  190</a></span>  <a class="code hl_enumeration" href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">Reduction</a> <a class="code hl_variable" href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">reduction_</a>;</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>};</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span> </div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span> </div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>}  <span class="comment">// namespace nn</span></div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span> </div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span><span class="preprocessor">#endif  </span><span class="comment">// LLM_CPP__NN_HPP_</span></div>
<div class="ttc" id="aParameter_8hpp_html"><div class="ttname"><a href="Parameter_8hpp.html">Parameter.hpp</a></div></div>
<div class="ttc" id="aabseil-cpp_2absl_2container_2btree__benchmark_8cc_html_a717c50cfde3924051c279a89096afd3d"><div class="ttname"><a href="abseil-cpp_2absl_2container_2btree__benchmark_8cc.html#a717c50cfde3924051c279a89096afd3d">i</a></div><div class="ttdeci">uint64_t i</div><div class="ttdef"><b>Definition</b> btree_benchmark.cc:232</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2container_2internal_2layout__test_8cc_html_ad66453096871179e6c6effe0df4b483b"><div class="ttname"><a href="abseil-cpp_2absl_2container_2internal_2layout__test_8cc.html#ad66453096871179e6c6effe0df4b483b">b</a></div><div class="ttdeci">uint64_t b</div><div class="ttdef"><b>Definition</b> layout_test.cc:58</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2hash_2internal_2city__test_8cc_html_ac54ae397901fe700628cafadea3c5208"><div class="ttname"><a href="abseil-cpp_2absl_2hash_2internal_2city__test_8cc.html#ac54ae397901fe700628cafadea3c5208">C</a></div><div class="ttdeci">#define C(x)</div><div class="ttdef"><b>Definition</b> city_test.cc:49</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2log_2check_8h_html_a3e1cfef60e774a81f30eaddf26a3a274"><div class="ttname"><a href="abseil-cpp_2absl_2log_2check_8h.html#a3e1cfef60e774a81f30eaddf26a3a274">CHECK</a></div><div class="ttdeci">#define CHECK(condition)</div><div class="ttdef"><b>Definition</b> check.h:57</div></div>
<div class="ttc" id="aabseil-cpp_2absl_2log_2check_8h_html_a7c0ce053b28d53aa4eaf3eb7fb71663b"><div class="ttname"><a href="abseil-cpp_2absl_2log_2check_8h.html#a7c0ce053b28d53aa4eaf3eb7fb71663b">CHECK_EQ</a></div><div class="ttdeci">#define CHECK_EQ(val1, val2)</div><div class="ttdef"><b>Definition</b> check.h:116</div></div>
<div class="ttc" id="aclassEigen_1_1TensorBase_html_ac18f87a86c01efc64d8f7235596d5d7d"><div class="ttname"><a href="classEigen_1_1TensorBase.html#ac18f87a86c01efc64d8f7235596d5d7d">Eigen::TensorBase::device</a></div><div class="ttdeci">TensorDevice&lt; Derived, DeviceType &gt; device(const DeviceType &amp;dev)</div><div class="ttdef"><b>Definition</b> TensorBase.h:1145</div></div>
<div class="ttc" id="aclassEigen_1_1TensorBase_html_adc5c658be289d8944ca3c8e7a2fac1f7"><div class="ttname"><a href="classEigen_1_1TensorBase.html#adc5c658be289d8944ca3c8e7a2fac1f7">Eigen::TensorBase::reshape</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const TensorReshapingOp&lt; const NewDimensions, const Derived &gt; reshape(const NewDimensions &amp;newDimensions) const</div><div class="ttdef"><b>Definition</b> TensorBase.h:1055</div></div>
<div class="ttc" id="aclassEigen_1_1TensorMap_html"><div class="ttname"><a href="classEigen_1_1TensorMap.html">Eigen::TensorMap</a></div><div class="ttdoc">A tensor expression mapping an existing array of data.</div><div class="ttdef"><b>Definition</b> TensorMap.h:30</div></div>
<div class="ttc" id="aclassEigen_1_1TensorMap_html_a715f830bbfa94beb8b2deb053530afd6"><div class="ttname"><a href="classEigen_1_1TensorMap.html#a715f830bbfa94beb8b2deb053530afd6">Eigen::TensorMap::size</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index size() const</div><div class="ttdef"><b>Definition</b> TensorMap.h:135</div></div>
<div class="ttc" id="aclassEigen_1_1TensorMap_html_adfb930b8289836aad40d64171bde46a1"><div class="ttname"><a href="classEigen_1_1TensorMap.html#adfb930b8289836aad40d64171bde46a1">Eigen::TensorMap::dimension</a></div><div class="ttdeci">EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index dimension(Index n) const</div><div class="ttdef"><b>Definition</b> TensorMap.h:131</div></div>
<div class="ttc" id="aclassEigen_1_1array_html"><div class="ttname"><a href="classEigen_1_1array.html">Eigen::array</a></div><div class="ttdef"><b>Definition</b> EmulateArray.h:21</div></div>
<div class="ttc" id="aclassabsl_1_1Span_html"><div class="ttname"><a href="classabsl_1_1Span.html">absl::Span</a></div><div class="ttdef"><b>Definition</b> span.h:182</div></div>
<div class="ttc" id="aclassabsl_1_1Span_html_a92186c247036e10dd12603c09f8b8797"><div class="ttname"><a href="classabsl_1_1Span.html#a92186c247036e10dd12603c09f8b8797">absl::Span::size</a></div><div class="ttdeci">constexpr size_type size() const noexcept</div><div class="ttdef"><b>Definition</b> span.h:315</div></div>
<div class="ttc" id="adev_2cuda_2common_8h_html_a73bc90d2e378d172e206b528b3756c5a"><div class="ttname"><a href="dev_2cuda_2common_8h.html#a73bc90d2e378d172e206b528b3756c5a">floatX</a></div><div class="ttdeci">float floatX</div><div class="ttdef"><b>Definition</b> common.h:199</div></div>
<div class="ttc" id="anamespacenn_html"><div class="ttname"><a href="namespacenn.html">nn</a></div><div class="ttdef"><b>Definition</b> Embedding.hpp:11</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a353b6bc3af73be364a53c3ae80019bd3"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a353b6bc3af73be364a53c3ae80019bd3">nn::SoftmaxCrossEntropy::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:93</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a60b41ca5338568fc097834fbaabe8ec0"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a60b41ca5338568fc097834fbaabe8ec0">nn::SoftmaxCrossEntropy::reduction_</a></div><div class="ttdeci">Reduction reduction_</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:190</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a61c0fc7c4f30c38c37b2a69353aebfb8"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a61c0fc7c4f30c38c37b2a69353aebfb8">nn::SoftmaxCrossEntropy::SoftmaxCrossEntropy</a></div><div class="ttdeci">SoftmaxCrossEntropy(Reduction reduction=Reduction::MEAN)</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:96</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a7688dce4252afd47dbb64a0b5717ea2c"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a7688dce4252afd47dbb64a0b5717ea2c">nn::SoftmaxCrossEntropy::ForwardAndBackward</a></div><div class="ttdeci">static void ForwardAndBackward(typename TTypes&lt; T &gt;::ConstMatrix logits, typename TTypes&lt; T &gt;::ConstMatrix labels, typename TTypes&lt; T &gt;::Flat scratch, typename TTypes&lt; T &gt;::Flat loss, typename TTypes&lt; T &gt;::Matrix logit_grad)</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:143</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a8f693b30c7b9e1c382dce3cdd77a8b04"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04">nn::SoftmaxCrossEntropy::Reduction</a></div><div class="ttdeci">Reduction</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:94</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a8f693b30c7b9e1c382dce3cdd77a8b04a44fe5ec5ac95c2fce33759616a32a6ad"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04a44fe5ec5ac95c2fce33759616a32a6ad">nn::SoftmaxCrossEntropy::SUM</a></div><div class="ttdeci">@ SUM</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:94</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_a8f693b30c7b9e1c382dce3cdd77a8b04add36ad20b6e6cbc891022762da1b385d"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#a8f693b30c7b9e1c382dce3cdd77a8b04add36ad20b6e6cbc891022762da1b385d">nn::SoftmaxCrossEntropy::MEAN</a></div><div class="ttdeci">@ MEAN</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:94</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_abd096903b589b4f9575bfca0e5b7b49d"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#abd096903b589b4f9575bfca0e5b7b49d">nn::SoftmaxCrossEntropy::Backward</a></div><div class="ttdeci">void Backward(typename TTypes&lt; T &gt;::ConstMatrix probs, absl::Span&lt; const int &gt; targets, typename TTypes&lt; T &gt;::Matrix logits_grad)</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:122</div></div>
<div class="ttc" id="astructnn_1_1SoftmaxCrossEntropy_html_afb6a8fe2404484125128f5b2cafe7806"><div class="ttname"><a href="structnn_1_1SoftmaxCrossEntropy.html#afb6a8fe2404484125128f5b2cafe7806">nn::SoftmaxCrossEntropy::Forward</a></div><div class="ttdeci">void Forward(typename TTypes&lt; T &gt;::ConstMatrix logits, absl::Span&lt; const int &gt; targets, typename TTypes&lt; T &gt;::Matrix probs, float *loss)</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:99</div></div>
<div class="ttc" id="astructnn_1_1Softmax_html_a1552ecc513a69adec694e31a57bc926d"><div class="ttname"><a href="structnn_1_1Softmax.html#a1552ecc513a69adec694e31a57bc926d">nn::Softmax::Backward</a></div><div class="ttdeci">static void Backward(typename TTypes&lt; T &gt;::ConstMatrix y, typename TTypes&lt; T &gt;::ConstMatrix y_grad, typename TTypes&lt; T &gt;::Matrix x_grad)</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:39</div></div>
<div class="ttc" id="astructnn_1_1Softmax_html_ad89595ce55976d7e45283370ca51fb5c"><div class="ttname"><a href="structnn_1_1Softmax.html#ad89595ce55976d7e45283370ca51fb5c">nn::Softmax::Forward</a></div><div class="ttdeci">static void Forward(typename TTypes&lt; T &gt;::ConstMatrix x, typename TTypes&lt; T &gt;::Matrix y)</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:16</div></div>
<div class="ttc" id="astructnn_1_1Softmax_html_af7722532871a3341255166920486e0aa"><div class="ttname"><a href="structnn_1_1Softmax.html#af7722532871a3341255166920486e0aa">nn::Softmax::T</a></div><div class="ttdeci">floatX T</div><div class="ttdef"><b>Definition</b> SoftMax.hpp:14</div></div>
<div class="ttc" id="atensor_2tensor__util_8hpp_html"><div class="ttname"><a href="tensor_2tensor__util_8hpp.html">tensor_util.hpp</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
