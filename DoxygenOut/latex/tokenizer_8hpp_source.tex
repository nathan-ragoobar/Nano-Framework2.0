\doxysection{tokenizer.\+hpp}
\hypertarget{tokenizer_8hpp_source}{}\label{tokenizer_8hpp_source}\index{llmc/tokenizer.hpp@{llmc/tokenizer.hpp}}
\mbox{\hyperlink{tokenizer_8hpp}{Go to the documentation of this file.}}
\begin{DoxyCode}{0}
\DoxyCodeLine{00001\ \textcolor{preprocessor}{\#ifndef\ TOKENIZER\_HPP}}
\DoxyCodeLine{00002\ \textcolor{preprocessor}{\#define\ TOKENIZER\_HPP}}
\DoxyCodeLine{00003\ }
\DoxyCodeLine{00004\ \textcolor{preprocessor}{\#include\ <string>}}
\DoxyCodeLine{00005\ \textcolor{preprocessor}{\#include\ <vector>}}
\DoxyCodeLine{00006\ \textcolor{preprocessor}{\#include\ <unordered\_map>}}
\DoxyCodeLine{00007\ \textcolor{preprocessor}{\#include\ <cstdint>}}
\DoxyCodeLine{00008\ \textcolor{preprocessor}{\#include\ "{}\mbox{\hyperlink{llmc_2utils_8h}{utils.h}}"{}}}
\DoxyCodeLine{00009\ }
\DoxyCodeLine{00010\ \textcolor{keyword}{namespace\ }\mbox{\hyperlink{namespacenano}{nano}}\ \{}
\DoxyCodeLine{00011\ }
\DoxyCodeLine{00012\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classnano_1_1Tokenizer}{Tokenizer}}\ \{}
\DoxyCodeLine{00013\ \textcolor{keyword}{private}:}
\DoxyCodeLine{00014\ \ \ \ \ std::vector<std::string>\ tokens\_;}
\DoxyCodeLine{00015\ \ \ \ \ std::unordered\_map<std::string,\ uint32\_t>\ token\_to\_id\_;}
\DoxyCodeLine{00016\ \ \ \ \ uint32\_t\ vocab\_size\_;}
\DoxyCodeLine{00017\ \ \ \ \ uint32\_t\ eot\_token\_;}
\DoxyCodeLine{00018\ \ \ \ \ \textcolor{keywordtype}{bool}\ init\_ok\_;}
\DoxyCodeLine{00019\ }
\DoxyCodeLine{00020\ \ \ \ \ \ \textcolor{comment}{//\ Helper\ for\ longest\ token\ match}}
\DoxyCodeLine{00021\ \ \ \ \ std::pair<uint32\_t,\ size\_t>\ find\_longest\_token(\textcolor{keyword}{const}\ std::string\&\ text,\ \textcolor{keywordtype}{size\_t}\ start)\textcolor{keyword}{\ const\ }\{}
\DoxyCodeLine{00022\ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{size\_t}\ longest\_len\ =\ 0;}
\DoxyCodeLine{00023\ \ \ \ \ \ \ \ \ uint32\_t\ token\_id\ =\ UINT32\_MAX;}
\DoxyCodeLine{00024\ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{00025\ \ \ \ \ \ \ \ \ \textcolor{comment}{//\ Try\ each\ possible\ substring\ starting\ at\ 'start'}}
\DoxyCodeLine{00026\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ (\textcolor{keywordtype}{size\_t}\ end\ =\ start\ +\ 1;\ end\ <=\ text.length();\ end++)\ \{}
\DoxyCodeLine{00027\ \ \ \ \ \ \ \ \ \ \ \ \ std::string\ substr\ =\ text.substr(start,\ end\ -\/\ start);}
\DoxyCodeLine{00028\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{auto}\ it\ =\ token\_to\_id\_.find(substr);}
\DoxyCodeLine{00029\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (it\ !=\ token\_to\_id\_.end()\ \&\&\ substr.length()\ >\ longest\_len)\ \{}
\DoxyCodeLine{00030\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ longest\_len\ =\ substr.length();}
\DoxyCodeLine{00031\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ token\_id\ =\ it-\/>second;}
\DoxyCodeLine{00032\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00033\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00034\ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{00035\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \{token\_id,\ longest\_len\};}
\DoxyCodeLine{00036\ \ \ \ \ \}}
\DoxyCodeLine{00037\ }
\DoxyCodeLine{00038\ \textcolor{keyword}{public}:}
\DoxyCodeLine{00039\ \ \ \ \ \mbox{\hyperlink{classnano_1_1Tokenizer_af4aa6ac127d60c0efddba19d048701ce}{Tokenizer}}()\ :\ init\_ok\_(false)\ \{\}}
\DoxyCodeLine{00040\ }
\DoxyCodeLine{00041\ \ \ \ \ \textcolor{keywordtype}{void}\ \mbox{\hyperlink{classnano_1_1Tokenizer_a091513890e0dfabd1f86040b6737f948}{init}}(\textcolor{keyword}{const}\ std::string\&\ dict\_file=\textcolor{stringliteral}{"{}./llmc/gpt2.txt"{}})\ \{}
\DoxyCodeLine{00042\ \ \ \ \ \ \ \ \ FILE*\ file\ =\ fopen(dict\_file.c\_str(),\ \textcolor{stringliteral}{"{}r"{}});}
\DoxyCodeLine{00043\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (!file)\ \{}
\DoxyCodeLine{00044\ \ \ \ \ \ \ \ \ \ \ \ \ fprintf(stderr,\ \textcolor{stringliteral}{"{}Failed\ to\ open\ dictionary\ file:\ \%s\(\backslash\)n"{}},\ dict\_file.c\_str());}
\DoxyCodeLine{00045\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return};}
\DoxyCodeLine{00046\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00047\ }
\DoxyCodeLine{00048\ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{char}\ line[1024];}
\DoxyCodeLine{00049\ \ \ \ \ \ \ \ \ uint32\_t\ token\_id\ =\ 0;}
\DoxyCodeLine{00050\ \ \ \ \ \ \ \ \ tokens\_.clear();}
\DoxyCodeLine{00051\ \ \ \ \ \ \ \ \ token\_to\_id\_.clear();}
\DoxyCodeLine{00052\ }
\DoxyCodeLine{00053\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{while}\ (fgets(line,\ \textcolor{keyword}{sizeof}(line),\ file))\ \{}
\DoxyCodeLine{00054\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{size\_t}\ \mbox{\hyperlink{abseil-cpp_2absl_2base_2internal_2low__level__alloc__test_8cc_afed088663f8704004425cdae2120b9b3}{len}}\ =\ strlen(line);}
\DoxyCodeLine{00055\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (\mbox{\hyperlink{abseil-cpp_2absl_2base_2internal_2low__level__alloc__test_8cc_afed088663f8704004425cdae2120b9b3}{len}}\ >\ 0\ \&\&\ line[\mbox{\hyperlink{abseil-cpp_2absl_2base_2internal_2low__level__alloc__test_8cc_afed088663f8704004425cdae2120b9b3}{len}}-\/1]\ ==\ \textcolor{charliteral}{'\(\backslash\)n'})\ \{}
\DoxyCodeLine{00056\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ line[\mbox{\hyperlink{abseil-cpp_2absl_2base_2internal_2low__level__alloc__test_8cc_afed088663f8704004425cdae2120b9b3}{len}}-\/1]\ =\ \textcolor{charliteral}{'\(\backslash\)0'};}
\DoxyCodeLine{00057\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00058\ }
\DoxyCodeLine{00059\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{char}*\ token\ =\ strtok(line,\ \textcolor{stringliteral}{"{}\(\backslash\)t"{}});}
\DoxyCodeLine{00060\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{char}*\ id\_str\ =\ strtok(NULL,\ \textcolor{stringliteral}{"{}\(\backslash\)t"{}});}
\DoxyCodeLine{00061\ \ \ \ \ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{00062\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (id\_str)\ \{}
\DoxyCodeLine{00063\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ token\_id\ =\ std::stoul(id\_str);}
\DoxyCodeLine{00064\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00065\ }
\DoxyCodeLine{00066\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{//\ Ensure\ vector\ has\ space}}
\DoxyCodeLine{00067\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (token\_id\ >=\ tokens\_.size())\ \{}
\DoxyCodeLine{00068\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ tokens\_.resize(token\_id\ +\ 1);}
\DoxyCodeLine{00069\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00070\ \ \ \ \ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{00071\ \ \ \ \ \ \ \ \ \ \ \ \ tokens\_[token\_id]\ =\ token;}
\DoxyCodeLine{00072\ \ \ \ \ \ \ \ \ \ \ \ \ token\_to\_id\_[token]\ =\ token\_id;}
\DoxyCodeLine{00073\ \ \ \ \ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{00074\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (!id\_str)\ \{}
\DoxyCodeLine{00075\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ token\_id++;}
\DoxyCodeLine{00076\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00077\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00078\ }
\DoxyCodeLine{00079\ \ \ \ \ \ \ \ \ vocab\_size\_\ =\ tokens\_.size();}
\DoxyCodeLine{00080\ \ \ \ \ \ \ \ \ eot\_token\_\ =\ token\_to\_id\_[\textcolor{stringliteral}{"{}<|endoftext|>"{}}];}
\DoxyCodeLine{00081\ \ \ \ \ \ \ \ \ init\_ok\_\ =\ \textcolor{keyword}{true};}
\DoxyCodeLine{00082\ }
\DoxyCodeLine{00083\ \ \ \ \ \ \ \ \ \mbox{\hyperlink{llmc_2utils_8h_ae094d98ede0500b8f5acba043487a5c1}{fcloseCheck}}(file);}
\DoxyCodeLine{00084\ \ \ \ \ \}}
\DoxyCodeLine{00085\ }
\DoxyCodeLine{00086\ \ \ \ \ std::vector<uint32\_t>\ \mbox{\hyperlink{classnano_1_1Tokenizer_a38ea2f6e014881ec603c53681ad62bcb}{encode\_string}}(\textcolor{keyword}{const}\ std::string\&\ text)\textcolor{keyword}{\ const\ }\{}
\DoxyCodeLine{00087\ \ \ \ \ \ \ \ \ std::vector<uint32\_t>\ result;}
\DoxyCodeLine{00088\ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{size\_t}\ pos\ =\ 0;}
\DoxyCodeLine{00089\ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{00090\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{while}\ (pos\ <\ text.length())\ \{}
\DoxyCodeLine{00091\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{auto}\ [token\_id,\ length]\ =\ find\_longest\_token(text,\ pos);}
\DoxyCodeLine{00092\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (token\_id\ ==\ UINT32\_MAX\ ||\ length\ ==\ 0)\ \{}
\DoxyCodeLine{00093\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{//\ No\ token\ found,\ move\ forward\ by\ one\ byte}}
\DoxyCodeLine{00094\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ pos++;}
\DoxyCodeLine{00095\ \ \ \ \ \ \ \ \ \ \ \ \ \}\ \textcolor{keywordflow}{else}\ \{}
\DoxyCodeLine{00096\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ result.push\_back(token\_id);}
\DoxyCodeLine{00097\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ pos\ +=\ length;}
\DoxyCodeLine{00098\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00099\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00100\ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{00101\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ result;}
\DoxyCodeLine{00102\ \ \ \ \ \}}
\DoxyCodeLine{00103\ }
\DoxyCodeLine{00104\ \ \ \ \ std::string\ \mbox{\hyperlink{classnano_1_1Tokenizer_acd7d27dd429b6a47585df9e8f19775d3}{decode\_string}}(\textcolor{keyword}{const}\ std::vector<uint32\_t>\&\ token\_ids)\textcolor{keyword}{\ const\ }\{}
\DoxyCodeLine{00105\ \ \ \ \ \ \ \ \ std::string\ result;}
\DoxyCodeLine{00106\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ (uint32\_t\ \textcolor{keywordtype}{id}\ :\ token\_ids)\ \{}
\DoxyCodeLine{00107\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (\textcolor{keywordtype}{id}\ <\ vocab\_size\_)\ \{}
\DoxyCodeLine{00108\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ result\ +=\ tokens\_[id];}
\DoxyCodeLine{00109\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00110\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00111\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ result;}
\DoxyCodeLine{00112\ \ \ \ \ \}}
\DoxyCodeLine{00113\ }
\DoxyCodeLine{00114\ \ \ \ \ std::string\ \mbox{\hyperlink{classnano_1_1Tokenizer_a93950479645e5f527c59b368902ee4c0}{decode\_string}}(\textcolor{keyword}{const}\ \textcolor{keywordtype}{int}*\ gen\_tokens,\ \textcolor{keywordtype}{size\_t}\ length)\textcolor{keyword}{\ const\ }\{}
\DoxyCodeLine{00115\ \ \ \ \ \ \ \ \ std::string\ result;}
\DoxyCodeLine{00116\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ (\textcolor{keywordtype}{size\_t}\ \mbox{\hyperlink{abseil-cpp_2absl_2container_2btree__benchmark_8cc_a717c50cfde3924051c279a89096afd3d}{i}}\ =\ 0;\ \mbox{\hyperlink{abseil-cpp_2absl_2container_2btree__benchmark_8cc_a717c50cfde3924051c279a89096afd3d}{i}}\ <\ length;\ ++\mbox{\hyperlink{abseil-cpp_2absl_2container_2btree__benchmark_8cc_a717c50cfde3924051c279a89096afd3d}{i}})\ \{}
\DoxyCodeLine{00117\ \ \ \ \ \ \ \ \ \ \ \ \ uint32\_t\ \textcolor{keywordtype}{id}\ =\ gen\_tokens[\mbox{\hyperlink{abseil-cpp_2absl_2container_2btree__benchmark_8cc_a717c50cfde3924051c279a89096afd3d}{i}}];}
\DoxyCodeLine{00118\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (\textcolor{keywordtype}{id}\ <\ vocab\_size\_)\ \{}
\DoxyCodeLine{00119\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ result\ +=\ tokens\_[id];}
\DoxyCodeLine{00120\ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00121\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00122\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ result;}
\DoxyCodeLine{00123\ \ \ \ \ \}}
\DoxyCodeLine{00124\ }
\DoxyCodeLine{00125\ \ \ \ \ uint32\_t\ \mbox{\hyperlink{classnano_1_1Tokenizer_a7bdb012432804c1965120af3e2017794}{encode}}(\textcolor{keyword}{const}\ std::string\&\ token)\textcolor{keyword}{\ const\ }\{}
\DoxyCodeLine{00126\ \ \ \ \ \ \ \ \ \textcolor{keyword}{auto}\ it\ =\ token\_to\_id\_.find(token);}
\DoxyCodeLine{00127\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (it\ !=\ token\_to\_id\_.end())\ \{}
\DoxyCodeLine{00128\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ it-\/>second;}
\DoxyCodeLine{00129\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00130\ \ \ \ \ \ \ \ \ fprintf(stderr,\ \textcolor{stringliteral}{"{}Token\ not\ found:\ \%s\(\backslash\)n"{}},\ token.c\_str());}
\DoxyCodeLine{00131\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ UINT32\_MAX;}
\DoxyCodeLine{00132\ \ \ \ \ \}}
\DoxyCodeLine{00133\ }
\DoxyCodeLine{00134\ \ \ \ \ std::string\ \mbox{\hyperlink{classnano_1_1Tokenizer_a2802694370444a51994f4b34cf8aef88}{decode}}(uint32\_t\ token\_id)\textcolor{keyword}{\ const\ }\{}
\DoxyCodeLine{00135\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (!init\_ok\_)\ \{}
\DoxyCodeLine{00136\ \ \ \ \ \ \ \ \ \ \ \ \ fprintf(stderr,\ \textcolor{stringliteral}{"{}Tokenizer\ not\ initialized\(\backslash\)n"{}});}
\DoxyCodeLine{00137\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{stringliteral}{"{}"{}};}
\DoxyCodeLine{00138\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00139\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (token\_id\ >=\ vocab\_size\_)\ \{}
\DoxyCodeLine{00140\ \ \ \ \ \ \ \ \ \ \ \ \ fprintf(stderr,\ \textcolor{stringliteral}{"{}Invalid\ token\ ID:\ \%u\(\backslash\)n"{}},\ token\_id);}
\DoxyCodeLine{00141\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{stringliteral}{"{}"{}};}
\DoxyCodeLine{00142\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{00143\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ tokens\_[token\_id];}
\DoxyCodeLine{00144\ \ \ \ \ \}}
\DoxyCodeLine{00145\ }
\DoxyCodeLine{00146\ \ \ \ \ uint32\_t\ \mbox{\hyperlink{classnano_1_1Tokenizer_a35001b5502eba225143279c7c40b391d}{get\_vocab\_size}}()\textcolor{keyword}{\ const\ }\{\ \textcolor{keywordflow}{return}\ vocab\_size\_;\ \}}
\DoxyCodeLine{00147\ \ \ \ \ uint32\_t\ \mbox{\hyperlink{classnano_1_1Tokenizer_a80137f5bff7fa4a734dc7b16a097b8ac}{get\_eot\_token}}()\textcolor{keyword}{\ const\ }\{\ \textcolor{keywordflow}{return}\ eot\_token\_;\ \}}
\DoxyCodeLine{00148\ \ \ \ \ \textcolor{keywordtype}{bool}\ \mbox{\hyperlink{classnano_1_1Tokenizer_a962c2da77906342d02f80e3916bad5e2}{is\_initialized}}()\textcolor{keyword}{\ const\ }\{\ \textcolor{keywordflow}{return}\ init\_ok\_;\ \}}
\DoxyCodeLine{00149\ \};}
\DoxyCodeLine{00150\ }
\DoxyCodeLine{00151\ \}\ \textcolor{comment}{//\ namespace\ nano}}
\DoxyCodeLine{00152\ }
\DoxyCodeLine{00153\ \textcolor{preprocessor}{\#endif}}

\end{DoxyCode}
