\doxysection{nano\+::Tokenizer Class Reference}
\hypertarget{classnano_1_1Tokenizer}{}\label{classnano_1_1Tokenizer}\index{nano::Tokenizer@{nano::Tokenizer}}


{\ttfamily \#include $<$tokenizer.\+hpp$>$}

\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classnano_1_1Tokenizer_af4aa6ac127d60c0efddba19d048701ce}{Tokenizer}} ()
\item 
void \mbox{\hyperlink{classnano_1_1Tokenizer_a091513890e0dfabd1f86040b6737f948}{init}} (const std\+::string \&dict\+\_\+file="{}./llmc/gpt2.\+txt"{})
\item 
std\+::vector$<$ uint32\+\_\+t $>$ \mbox{\hyperlink{classnano_1_1Tokenizer_a38ea2f6e014881ec603c53681ad62bcb}{encode\+\_\+string}} (const std\+::string \&text) const
\item 
std\+::string \mbox{\hyperlink{classnano_1_1Tokenizer_acd7d27dd429b6a47585df9e8f19775d3}{decode\+\_\+string}} (const std\+::vector$<$ uint32\+\_\+t $>$ \&token\+\_\+ids) const
\item 
std\+::string \mbox{\hyperlink{classnano_1_1Tokenizer_a93950479645e5f527c59b368902ee4c0}{decode\+\_\+string}} (const int \texorpdfstring{$\ast$}{*}gen\+\_\+tokens, size\+\_\+t length) const
\item 
uint32\+\_\+t \mbox{\hyperlink{classnano_1_1Tokenizer_a7bdb012432804c1965120af3e2017794}{encode}} (const std\+::string \&token) const
\item 
std\+::string \mbox{\hyperlink{classnano_1_1Tokenizer_a2802694370444a51994f4b34cf8aef88}{decode}} (uint32\+\_\+t token\+\_\+id) const
\item 
uint32\+\_\+t \mbox{\hyperlink{classnano_1_1Tokenizer_a35001b5502eba225143279c7c40b391d}{get\+\_\+vocab\+\_\+size}} () const
\item 
uint32\+\_\+t \mbox{\hyperlink{classnano_1_1Tokenizer_a80137f5bff7fa4a734dc7b16a097b8ac}{get\+\_\+eot\+\_\+token}} () const
\item 
bool \mbox{\hyperlink{classnano_1_1Tokenizer_a962c2da77906342d02f80e3916bad5e2}{is\+\_\+initialized}} () const
\end{DoxyCompactItemize}


\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classnano_1_1Tokenizer_af4aa6ac127d60c0efddba19d048701ce}\index{nano::Tokenizer@{nano::Tokenizer}!Tokenizer@{Tokenizer}}
\index{Tokenizer@{Tokenizer}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{Tokenizer()}{Tokenizer()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_af4aa6ac127d60c0efddba19d048701ce} 
nano\+::\+Tokenizer\+::\+Tokenizer (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



\doxysubsection{Member Function Documentation}
\Hypertarget{classnano_1_1Tokenizer_a2802694370444a51994f4b34cf8aef88}\index{nano::Tokenizer@{nano::Tokenizer}!decode@{decode}}
\index{decode@{decode}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{decode()}{decode()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a2802694370444a51994f4b34cf8aef88} 
std\+::string nano\+::\+Tokenizer\+::decode (\begin{DoxyParamCaption}\item[{uint32\+\_\+t}]{token\+\_\+id}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=291pt]{classnano_1_1Tokenizer_a2802694370444a51994f4b34cf8aef88_icgraph}
\end{center}
\end{figure}
\Hypertarget{classnano_1_1Tokenizer_a93950479645e5f527c59b368902ee4c0}\index{nano::Tokenizer@{nano::Tokenizer}!decode\_string@{decode\_string}}
\index{decode\_string@{decode\_string}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{decode\_string()}{decode\_string()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a93950479645e5f527c59b368902ee4c0} 
std\+::string nano\+::\+Tokenizer\+::decode\+\_\+string (\begin{DoxyParamCaption}\item[{const int \texorpdfstring{$\ast$}{*}}]{gen\+\_\+tokens}{, }\item[{size\+\_\+t}]{length}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classnano_1_1Tokenizer_acd7d27dd429b6a47585df9e8f19775d3}\index{nano::Tokenizer@{nano::Tokenizer}!decode\_string@{decode\_string}}
\index{decode\_string@{decode\_string}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{decode\_string()}{decode\_string()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_acd7d27dd429b6a47585df9e8f19775d3} 
std\+::string nano\+::\+Tokenizer\+::decode\+\_\+string (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ uint32\+\_\+t $>$ \&}]{token\+\_\+ids}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=291pt]{classnano_1_1Tokenizer_acd7d27dd429b6a47585df9e8f19775d3_icgraph}
\end{center}
\end{figure}
\Hypertarget{classnano_1_1Tokenizer_a7bdb012432804c1965120af3e2017794}\index{nano::Tokenizer@{nano::Tokenizer}!encode@{encode}}
\index{encode@{encode}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{encode()}{encode()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a7bdb012432804c1965120af3e2017794} 
uint32\+\_\+t nano\+::\+Tokenizer\+::encode (\begin{DoxyParamCaption}\item[{const std\+::string \&}]{token}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classnano_1_1Tokenizer_a38ea2f6e014881ec603c53681ad62bcb}\index{nano::Tokenizer@{nano::Tokenizer}!encode\_string@{encode\_string}}
\index{encode\_string@{encode\_string}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{encode\_string()}{encode\_string()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a38ea2f6e014881ec603c53681ad62bcb} 
std\+::vector$<$ uint32\+\_\+t $>$ nano\+::\+Tokenizer\+::encode\+\_\+string (\begin{DoxyParamCaption}\item[{const std\+::string \&}]{text}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=291pt]{classnano_1_1Tokenizer_a38ea2f6e014881ec603c53681ad62bcb_icgraph}
\end{center}
\end{figure}
\Hypertarget{classnano_1_1Tokenizer_a80137f5bff7fa4a734dc7b16a097b8ac}\index{nano::Tokenizer@{nano::Tokenizer}!get\_eot\_token@{get\_eot\_token}}
\index{get\_eot\_token@{get\_eot\_token}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{get\_eot\_token()}{get\_eot\_token()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a80137f5bff7fa4a734dc7b16a097b8ac} 
uint32\+\_\+t nano\+::\+Tokenizer\+::get\+\_\+eot\+\_\+token (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classnano_1_1Tokenizer_a35001b5502eba225143279c7c40b391d}\index{nano::Tokenizer@{nano::Tokenizer}!get\_vocab\_size@{get\_vocab\_size}}
\index{get\_vocab\_size@{get\_vocab\_size}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{get\_vocab\_size()}{get\_vocab\_size()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a35001b5502eba225143279c7c40b391d} 
uint32\+\_\+t nano\+::\+Tokenizer\+::get\+\_\+vocab\+\_\+size (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}

\Hypertarget{classnano_1_1Tokenizer_a091513890e0dfabd1f86040b6737f948}\index{nano::Tokenizer@{nano::Tokenizer}!init@{init}}
\index{init@{init}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{init()}{init()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a091513890e0dfabd1f86040b6737f948} 
void nano\+::\+Tokenizer\+::init (\begin{DoxyParamCaption}\item[{const std\+::string \&}]{dict\+\_\+file}{ = {\ttfamily "{}./llmc/gpt2.txt"{}}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=282pt]{classnano_1_1Tokenizer_a091513890e0dfabd1f86040b6737f948_icgraph}
\end{center}
\end{figure}
\Hypertarget{classnano_1_1Tokenizer_a962c2da77906342d02f80e3916bad5e2}\index{nano::Tokenizer@{nano::Tokenizer}!is\_initialized@{is\_initialized}}
\index{is\_initialized@{is\_initialized}!nano::Tokenizer@{nano::Tokenizer}}
\doxysubsubsection{\texorpdfstring{is\_initialized()}{is\_initialized()}}
{\footnotesize\ttfamily \label{classnano_1_1Tokenizer_a962c2da77906342d02f80e3916bad5e2} 
bool nano\+::\+Tokenizer\+::is\+\_\+initialized (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
llmc/\mbox{\hyperlink{tokenizer_8hpp}{tokenizer.\+hpp}}\end{DoxyCompactItemize}
